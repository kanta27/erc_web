<!DOCTYPE html><html><head><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.14.0/css/all.css" integrity="sha384-HzLeBuhoNPvSl5KYnjx0BT+WB0QEEqLprO+NBkkk5gbc67FTaL7XIGa2w1L0Xbgc" crossorigin="anonymous"/><meta name="viewport" content="width=device-width, initial-scale=1" class="jsx-5c406e1c43a4c1e0"/><meta charSet="utf-8" class="jsx-5c406e1c43a4c1e0"/><title class="jsx-5c406e1c43a4c1e0">ERC: Sensor Fusion</title><meta name="Description" class="jsx-5c406e1c43a4c1e0"/><meta name="next-head-count" content="4"/><link rel="preload" href="/ERC-website-2021/_next/static/css/1e14cc6db1e7a797.css" as="style"/><link rel="stylesheet" href="/ERC-website-2021/_next/static/css/1e14cc6db1e7a797.css" data-n-g=""/><link rel="preload" href="/ERC-website-2021/_next/static/css/b4c3d7a1b2745c28.css" as="style"/><link rel="stylesheet" href="/ERC-website-2021/_next/static/css/b4c3d7a1b2745c28.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/ERC-website-2021/_next/static/chunks/polyfills-5cd94c89d3acac5f.js"></script><script src="/ERC-website-2021/_next/static/chunks/webpack-fa43d853eceb8330.js" defer=""></script><script src="/ERC-website-2021/_next/static/chunks/framework-91d7f78b5b4003c8.js" defer=""></script><script src="/ERC-website-2021/_next/static/chunks/main-7f98c67519643b43.js" defer=""></script><script src="/ERC-website-2021/_next/static/chunks/pages/_app-8cb99849f9af73f7.js" defer=""></script><script src="/ERC-website-2021/_next/static/chunks/147-3e7b67f404388648.js" defer=""></script><script src="/ERC-website-2021/_next/static/chunks/157-8d95c7b28c8fe8df.js" defer=""></script><script src="/ERC-website-2021/_next/static/chunks/pages/blog/%5Bslug%5D-771aa725b6e9cc01.js" defer=""></script><script src="/ERC-website-2021/_next/static/5QJC4znxUt28OyN5o0qMk/_buildManifest.js" defer=""></script><script src="/ERC-website-2021/_next/static/5QJC4znxUt28OyN5o0qMk/_ssgManifest.js" defer=""></script><script src="/ERC-website-2021/_next/static/5QJC4znxUt28OyN5o0qMk/_middlewareManifest.js" defer=""></script><style id="__jsx-5c406e1c43a4c1e0">@import url("https://fonts.googleapis.com/css?family=Work+Sans&display=swap");
* {box-sizing:inherit}
html {box-sizing:border-box;
overflow-y:scroll}
body {margin:0;
font-family:"Work Sans", "Helvetica Neue", Helvetica, sans-serif;
overflow-x:hidden;
color:#000;
font-size:16px;
-webkit-font-smoothing:antialiased;
-moz-osx-font-smoothing:grayscale}
a {-webkit-text-decoration:none;
text-decoration:none;
color:inherit;
-webkit-transition:opacity 0.2s ease;
transition:opacity 0.2s ease}
a:hover {-webkit-transition:opacity 0.2s ease;
transition:opacity 0.2s ease;
opacity:0.5;
text-decoration-color:inherit}
ul {list-style:none;
margin:0;
padding-bottom:0;
padding-left:0;
padding-right:0;
padding-top:0;
list-style-position:outside;
list-style-image:none}
ol {margin:0;
padding-bottom:0;
padding-left:0;
padding-right:0;
padding-top:0;
list-style-position:outside;
list-style-image:none}
ul, ol, p {margin-bottom:1.45rem}
img {max-width:100%}
img, figure, table, fieldset {margin-left:0;
margin-right:0;
margin-top:0;
padding-bottom:0;
padding-left:0;
padding-right:0;
padding-top:0;
margin-bottom:1.45rem}
pre {margin-left:0;
margin-right:0;
margin-top:0;
margin-bottom:1.45rem;
font-size:0.85rem;
line-height:1.42;
background:hsla(0, 0%, 0%, 0.04);
border-radius:3px;
overflow:auto;
word-wrap:normal;
padding:1.45rem}
table {font-size:1rem;
line-height:1.45rem;
border-collapse:collapse;
width:100%}
blockquote {margin-left:1.45rem;
margin-right:1.45rem;
margin-top:0;
padding-bottom:0;
padding-left:0;
padding-right:0;
padding-top:0;
margin-bottom:1.45rem}
strong {font-weight:bold}
li {margin-bottom:calc(1.45rem / 2)}
ol li {padding-left:0}
ul li {padding-left:0}
li >ol {margin-left:1.45rem;
margin-bottom:calc(1.45rem / 2);
margin-top:calc(1.45rem / 2)}
li >ul {margin-left:1.45rem;
margin-bottom:calc(1.45rem / 2);
margin-top:calc(1.45rem / 2)}
blockquote *:last-child {margin-bottom:0}
li *:last-child {margin-bottom:0}
p *:last-child {margin-bottom:0}
li >p {margin-bottom:calc(1.45rem / 2)}
code {font-size:0.85rem;
line-height:1.45rem}
h1, h2, h3, h4, h5, h6, p {font-family:"Work Sans", "Helvetica Neue", Helvetica, sans-serif;
margin-left:0;
margin-right:0;
margin-top:0;
padding-bottom:0;
padding-left:0;
padding-right:0;
padding-top:0;
margin-bottom:1.45rem;
color:inherit;
text-rendering:optimizeLegibility}
h1, h2 {font-weight:500}
h1 {font-size:2rem;
letter-spacing:-1px;
line-height:1.1875}
h2 {font-size:1.7rem;
letter-spacing:-0.75px;
line-height:1.2}
h3 {font-size:1.2rem;
letter-spacing:-0.5px;
line-height:1.1875;
color:#ffffff;
font-weight:normal}
p {font-size:1.2rem;
letter-spacing:-0.5px;
line-height:1.5;
color:#ffffff}
@media (min-width:1280px) {h1 {font-size:2rem;
letter-spacing:-1px;
line-height:1.1875}
h2 {font-size:1.5rem;
letter-spacing:-0.75px;
line-height:1.1667}
h3 {font-size:1rem;
letter-spacing:-0.5px;
line-height:1.1875;
color:#ffffff;
font-weight:normal}
p {line-height:1.4375}}</style><style id="__jsx-fad75cd775d05681">.blog.jsx-fad75cd775d05681 {background-color:#1D252E;
color:#ffffff;
margin-bottom:0}
.blog.jsx-fad75cd775d05681 h1.jsx-fad75cd775d05681 {margin-bottom:0.7rem}
.blog__hero.jsx-fad75cd775d05681 {min-height:300px;
height:60vh;
width:100%;
margin:0;
overflow:hidden}
.blog__hero.jsx-fad75cd775d05681 img.jsx-fad75cd775d05681 {margin-bottom:0;
object-fit:cover;
min-height:100%;
min-width:100%;
object-position:center}
.blog__info.jsx-fad75cd775d05681 {padding:1.5rem 1.25rem;
width:100%;
max-width:768px;
margin:0 auto}
.blog__info.jsx-fad75cd775d05681 h1.jsx-fad75cd775d05681 {margin-bottom:0.66rem}
.blog__info.jsx-fad75cd775d05681 h3.jsx-fad75cd775d05681 {margin-bottom:0}
.blog__body.jsx-fad75cd775d05681 {width:100%;
padding:0 1.25rem;
margin:0 auto;
display:-webkit-box;
display:-webkit-flex;
display:-ms-flexbox;
display:flex;
-webkit-flex-direction:column;
-ms-flex-direction:column;
flex-direction:column;
-webkit-justify-content:center;
justify-content:center}
.blog__body.jsx-fad75cd775d05681 a.jsx-fad75cd775d05681 {padding-bottom:1.5rem}
.blog__body.jsx-fad75cd775d05681:last-child {margin-bottom:0}
.blog__body.jsx-fad75cd775d05681 h1.jsx-fad75cd775d05681 h2.jsx-fad75cd775d05681 h3.jsx-fad75cd775d05681 h4.jsx-fad75cd775d05681 h5.jsx-fad75cd775d05681 h6.jsx-fad75cd775d05681 p.jsx-fad75cd775d05681 {font-weight:normal}
.blog__body.jsx-fad75cd775d05681 p.jsx-fad75cd775d05681 {color:#ffffff}
.blog__body.jsx-fad75cd775d05681 ul.jsx-fad75cd775d05681 {list-style:initial}
.blog__body.jsx-fad75cd775d05681 ul.jsx-fad75cd775d05681 ol.jsx-fad75cd775d05681 {margin-left:1.25rem;
margin-bottom:1.25rem;
padding-left:1.45rem}
.blog__footer.jsx-fad75cd775d05681 {display:-webkit-box;
display:-webkit-flex;
display:-ms-flexbox;
display:flex;
-webkit-box-pack:justify;
-webkit-justify-content:space-between;
justify-content:space-between;
-webkit-align-items:center;
-webkit-box-align:center;
-ms-flex-align:center;
align-items:center;
padding:1.5rem 1.25rem;
width:100%;
max-width:800px;
margin:0 auto}
.blog__footer.jsx-fad75cd775d05681 h2.jsx-fad75cd775d05681 {margin-bottom:0}
.blog__footer.jsx-fad75cd775d05681 a.jsx-fad75cd775d05681 {display:-webkit-box;
display:-webkit-flex;
display:-ms-flexbox;
display:flex;
-webkit-box-pack:justify;
-webkit-justify-content:space-between;
justify-content:space-between;
-webkit-align-items:center;
-webkit-box-align:center;
-ms-flex-align:center;
align-items:center}
.blog__footer.jsx-fad75cd775d05681 a.jsx-fad75cd775d05681 svg.jsx-fad75cd775d05681 {width:20px}
@media (min-width:768px) {.blog.jsx-fad75cd775d05681 {display:-webkit-box;
display:-webkit-flex;
display:-ms-flexbox;
display:flex;
-webkit-flex-direction:column;
-ms-flex-direction:column;
flex-direction:column}
.blog__body.jsx-fad75cd775d05681 {max-width:800px;
padding:0 2rem}
.blog__body.jsx-fad75cd775d05681 span.jsx-fad75cd775d05681 {width:100%;
margin:1.5rem auto}
.blog__body.jsx-fad75cd775d05681 ul.jsx-fad75cd775d05681 ol.jsx-fad75cd775d05681 {margin-left:1.5rem;
margin-bottom:1.5rem}
.blog__hero.jsx-fad75cd775d05681 {min-height:600px;
height:75vh}
.blog__info.jsx-fad75cd775d05681 {text-align:center;
padding:2rem 0}
.blog__info.jsx-fad75cd775d05681 h1.jsx-fad75cd775d05681 {max-width:500px;
margin:0 auto 0.66rem auto}
.blog__footer.jsx-fad75cd775d05681 {padding:2.25rem}}
@media (min-width:1440px) {.blog__hero.jsx-fad75cd775d05681 {height:70vh}
.blog__info.jsx-fad75cd775d05681 {padding:3rem 0}
.blog__footer.jsx-fad75cd775d05681 {padding:2rem 2rem 3rem 2rem}}</style><style id="__jsx-906dc5424778ca56">.layout.jsx-906dc5424778ca56 {overflow-x:hidden;
display:-webkit-box;
display:-webkit-flex;
display:-ms-flexbox;
display:flex;
-webkit-flex-direction:column;
-ms-flex-direction:column;
flex-direction:column;
min-height:100vh}
.layout.jsx-906dc5424778ca56 .info_page.jsx-906dc5424778ca56 {color:#ebebeb}
.content.jsx-906dc5424778ca56 {-webkit-box-flex:1;
-webkit-flex-grow:1;
-ms-flex-positive:1;
flex-grow:1}
@media (min-width:768px) {.layout.jsx-906dc5424778ca56 {display:block}
.content.jsx-906dc5424778ca56 {-webkit-box-flex:none;
-webkit-flex-grow:none;
-ms-flex-positive:none;
flex-grow:none;
width:100vw;
margin-left:0vw}}</style></head><body><div id="__next"><section style="background-color:undefined;color:false" class="jsx-906dc5424778ca56 layout false"><nav class="NavBar_navbar__D1PWG"><ul class="NavBar_list__ZV9KR"><li class="NavBar_buttons_view__Rf_gB"><a href="https://erciitb.github.io/website-2020/#home">Home</a></li><li class="NavBar_buttons_view__Rf_gB"><a href="/ERC-website-2021/blog">Blog</a></li><li class="NavBar_buttons_view__Rf_gB"><a href="https://erciitb.github.io/website-2020/#events">Events</a></li><li class="NavBar_buttons_view__Rf_gB"><a href="https://erciitb.github.io/website-2020/#ercteamdet">Team Details</a></li><li class="NavBar_buttons_view__Rf_gB"><a href="https://erciitb.github.io/website-2020/#contact">Contact Us</a></li></ul></nav><div class="NavBar_navbar_mobile__9duUE"><div class="NavBar_hamburger_icon_block__a5VwY"><button href="/" class="NavBar_hamburger_icon_button__3TwpQ">☰</button></div><nav class="NavBar_nav_menu___omdq"><ul class="NavBar_nav_menu_items__gPV7x"><li class="NavBar_buttons_view__Rf_gB"><a href="/ERC-website-2021/blog/sensor-fusion#">Close ×</a></li><li class="NavBar_buttons_view__Rf_gB"><a href="https://erciitb.github.io/website-2020/#home">Home</a></li><li class="NavBar_buttons_view__Rf_gB"><a href="/ERC-website-2021/blog">Blog</a></li><li class="NavBar_buttons_view__Rf_gB"><a href="https://erciitb.github.io/website-2020/#events">Events</a></li><li class="NavBar_buttons_view__Rf_gB"><a href="https://erciitb.github.io/website-2020/#ercteamdet">Team Details</a></li><li class="NavBar_buttons_view__Rf_gB"><a href="https://erciitb.github.io/website-2020/#contact">Contact Us</a></li></ul></nav></div><div class="jsx-906dc5424778ca56 content"><article class="jsx-fad75cd775d05681 blog"><figure class="jsx-fad75cd775d05681 blog__hero"><img src="/ERC-website-2021/static/fusion_sensors_cover.jpg" alt="blog_hero_Sensor Fusion" class="jsx-fad75cd775d05681"/></figure><div class="jsx-fad75cd775d05681 blog__info"><h1 class="jsx-fad75cd775d05681">Sensor Fusion</h1><h3 class="jsx-fad75cd775d05681">Nov 24 2021</h3></div><div class="jsx-fad75cd775d05681 blog__body"><p>Sensor Fusion refers to the process of combining measurements from different sources to ensure that resulting information has lesser uncertainty as compared to any of the individual measurements. As an example, we can calculate depth information from 2-D images by combining data from 2 cameras at slightly different locations.</p><p>The different sources for the information we obtain need not be identical. There are three types of fusion methods:</p><ul><li><strong>Direct Fusion:</strong> Fusion of data from a set of either heterogenous or homogenous set of sensors along with past history of sensor data</li><li><strong>Indirect Fusion:</strong> Along with sources in direct fusion, we also use sources like a priori knowledge about the information, and human input.</li><li><strong>Combination of both:</strong> We can also obtain information by combining the outputs of the above 2 methods of fusion</li></ul><h1>Classification of Sensor Fusion Algorithms</h1><p>Sensor Fusion algorithms can be classified on different parameters:</p><h2>On the basis of Abstraction Level (When?)</h2><ul><li><strong>Low Level Fusion:</strong> Fusing the raw data coming in from different sensors</li><li><strong>Mid Level Fusion:</strong> Fusing the detections from each sensor</li><li><strong>High Level Fusion:</strong> Fusing the trajectories (predictions) of each sensor</li></ul><p><img src="/ERC-website-2021/static/fusion_sensors_image3.png"/></p><h2>On the basis of Centralization Level (Where?)</h2><ul><li><strong>Centralized:</strong> A single central unit deals with the fusion</li><li><strong>Decentralized:</strong> Each sensor fuses the data and sends it onto the next one</li><li><strong>Distributed:</strong> Each sensor fuses data locally and sends it to the next unit</li></ul><p><img src="/ERC-website-2021/static/fusion_sensors_image2.png"/></p><h2>On the basis of Composition Level (What?)</h2><ul><li><strong>Competitive Fusion:</strong> When different sensors are meant for the same purpose</li><li><strong>Complementary Fusion:</strong> When different sensors are used to look at different scenes to obtain data that couldn’t have been obtained had the been used individually</li><li><strong>Coordinated Fusion:</strong> Using multiple sensors to produce a new scene, but looking at the same object. E.g. 3D reconstruction</li></ul><p><img src="/ERC-website-2021/static/fusion_sensors_image1.png"/></p><p>For more details regarding the types of sensor fusion, check <a title="https://www.thinkautonomous.ai/blog/?p=9-types-of-sensor-fusion-algorithms" href="https://www.thinkautonomous.ai/blog/?p=9-types-of-sensor-fusion-algorithms">here</a>.</p><p><strong>Example Calculation Regarding Sensor Fusion</strong></p><p>For a basic example showing how two measurements can be combined, check <a title="https://en.wikipedia.org/wiki/Sensor_fusion#Example_calculations" href="https://en.wikipedia.org/wiki/Sensor_fusion#Example_calculations">this</a> section.</p><h1>Algorithms on Sensor Fusion</h1><h2>Based on Sensor Fusion</h2><ul><li>The central limit theorem states that when we take a large number of measurements of a parameter, the distribution of their mean tends to a normal distribution, and the mean of the distribution gets closer to the true mean as number of measurements increase.</li><li>In order to see its relation to sensor fusion, assume we have two different sensors A and B. The more samples we take of their readings, the more closely the distribution of the sample averages will resemble a bell curve and thus approach the set’s true average value.  The closer we approach an accurate average value, the less noise will factor into sensor fusion algorithms.</li><li>For more information regarding the central limit theorem, check <a title="https://en.wikipedia.org/wiki/Central_limit_theorem" href="https://en.wikipedia.org/wiki/Central_limit_theorem">here</a>.</li></ul><h2>Based on Kalman Filter</h2><ul><li>A Kalman filter is an algorithm that estimates unknown values by taking data inputs from multiple sources, despite possibly having a high amount of signal noise.</li><li>It has the advantage of predicting unknown values more accurately by combining measurements than what is obtained on using the measurements individually.</li><li>The Kalman filter is a recursive algorithm that depends only on the previous state of the system and the current observed sensor data to estimate the current state of the system.</li><li>For more details regarding the Kalman filter, check <a title="https://www.kalmanfilter.net/default.aspx" href="https://www.kalmanfilter.net/default.aspx">here</a> or <a title="https://www.bzarg.com/p/how-a-kalman-filter-works-in-pictures/" href="https://www.bzarg.com/p/how-a-kalman-filter-works-in-pictures/">here</a>.</li></ul><h2>Based on Bayesian Networks</h2><ul><li>Bayes Rule in probability is the backbone of state update equations used for sensor fusion. Bayesian Networks based on Bayes rule predicts the likelihood that any given measurement is a contributing factor in determining a given parameter.</li><li>For a detailed study of Bayesian Networks, check <a title="https://en.wikipedia.org/wiki/Bayesian_network" href="https://en.wikipedia.org/wiki/Bayesian_network">here</a>.</li><li>Some of the algorithms used for Sensor Fusion based on Bayesian networks are <a title="http://web.cs.wpi.edu/~cs539/s05/Projects/k2_algorithm.pdf" href="http://web.cs.wpi.edu/~cs539/s05/Projects/k2_algorithm.pdf">K2</a>, <a title="https://www.geeksforgeeks.org/introduction-hill-climbing-artificial-intelligence/" href="https://www.geeksforgeeks.org/introduction-hill-climbing-artificial-intelligence/">hill climbing</a>, <a title="https://en.wikipedia.org/wiki/Simulated_annealing" href="https://en.wikipedia.org/wiki/Simulated_annealing">simulated annealing</a>.</li></ul><h2>The Dempster-Shafer Theory</h2><ul><li>This theory, called the theory of belief functions or the evidence theory, is a general framework for working with uncertainties and measurements.</li><li>Dempster–Shafer theory is based on two ideas: obtaining degrees of belief for one question from subjective probabilities for a related question, and Dempster&#x27;s rule for combining such degrees of belief when they are based on independent items of evidence.</li><li>For more details on this theory, check <a title="https://en.wikipedia.org/wiki/Dempster%E2%80%93Shafer_theory" href="https://en.wikipedia.org/wiki/Dempster%E2%80%93Shafer_theory">here</a> or <a title="https://www.geeksforgeeks.org/ml-dempster-shafer-theory/" href="https://www.geeksforgeeks.org/ml-dempster-shafer-theory/">here</a>.</li></ul><h2>Convolutional Neural Networks</h2><ul><li>Convolutional neural network based methods can simultaneously process many channels of sensor data. From this fusion of such data, they produce classification results based on image recognition.</li><li>For a detailed study of CNNs, check <a title="https://towardsdatascience.com/a-comprehensive-guide-to-convolutional-neural-networks-the-eli5-way-3bd2b1164a53" href="https://towardsdatascience.com/a-comprehensive-guide-to-convolutional-neural-networks-the-eli5-way-3bd2b1164a53">here</a>.</li></ul><h1>Conclusion</h1><p>Sensor Fusion is a vast field, with a huge number of algorithms to combine sensor data to obtain measurements. The mathematics behind sensor fusion is often complicated and requires a good understanding of concepts of probability. The goal of this article was to give a brief overview of different types of sensor fusion and to give a bird’s eye view of the various algorithms that can be used for sensor fusion.</p></div><h2 class="jsx-fad75cd775d05681 blog__footer">Written By: <!-- -->Govind Saju</h2></article></div><div class="contact-section" id="contact"><div class="contact-details"><p id="contact-text" class="hover-difference">Get directly in touch with us:</p><div class="contact-icons hover-difference"><a href="https://www.facebook.com/erciitb"><i class="fab fa-facebook-square"></i></a><a href="https://www.instagram.com/erc.iitb/"><i class="fab fa-instagram"></i></a><a href="mailto:erciitbombay@gmail.com"><i class="far fa-envelope"></i></a></div><a href="mailto:elecrobo.club@iitb.ac.in" id="contact-mail" class="hover-difference">elecrobo.club@iitb.ac.in</a><button class="contact-form-button">Message us</button></div><div class="contact-form-map-mix-outer"><div class="contact-form-map-mix-inner"><div class="contact-map"><iframe src="https://www.google.com/maps/embed?pb=!1m18!1m12!1m3!1d3169.6786880670256!2d72.9138437580561!3d19.13376545835707!2m3!1f0!2f0!3f0!3m2!1i1024!2i768!4f13.1!3m3!1m2!1s0x3be7c7f5e4ac7efd%3A0xd9d02f29b4617fb4!2sTinkerers&#x27;%20Laboratory!5e0!3m2!1sen!2sin!4v1597995010048!5m2!1sen!2sin" frameBorder="0" style="border:0" aria-hidden="false" tabindex="0"></iframe></div><div class="contact-form"><form action="./form-submit.php" method="POST" id="validated-form"><div class="contact-form-element"><label for="name">Name</label><input type="text" name="name" id="contact-user-name" required=""/></div><div class="contact-form-element"><label for="email">Email</label><input type="text" name="email" id="contact-user-email" required=""/></div><div class="contact-form-element"><label for="message">Message</label><textarea name="message" maxlength="10000" cols="30" rows="4" id="contact-user-message"></textarea></div></form></div></div></div></div></section></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"siteTitle":"ERC: Sensor Fusion","frontmatter":{"title":"Sensor Fusion","author":"Govind Saju","hero_image":"/ERC-website-2021/static/fusion_sensors_cover.jpg","date":"2021-11-24T12:30:00.000Z"},"markdownBody":"Sensor Fusion refers to the process of combining measurements from different sources to ensure that resulting information has lesser uncertainty as compared to any of the individual measurements. As an example, we can calculate depth information from 2-D images by combining data from 2 cameras at slightly different locations.\n\nThe different sources for the information we obtain need not be identical. There are three types of fusion methods:\n\n* **Direct Fusion:** Fusion of data from a set of either heterogenous or homogenous set of sensors along with past history of sensor data\n* **Indirect Fusion:** Along with sources in direct fusion, we also use sources like a priori knowledge about the information, and human input.\n* **Combination of both:** We can also obtain information by combining the outputs of the above 2 methods of fusion\n\n# Classification of Sensor Fusion Algorithms\n\nSensor Fusion algorithms can be classified on different parameters:\n\n## On the basis of Abstraction Level (When?)\n\n* **Low Level Fusion:** Fusing the raw data coming in from different sensors\n* **Mid Level Fusion:** Fusing the detections from each sensor\n* **High Level Fusion:** Fusing the trajectories (predictions) of each sensor\n\n![](/ERC-website-2021/static/fusion_sensors_image3.png)\n\n## On the basis of Centralization Level (Where?)\n\n* **Centralized:** A single central unit deals with the fusion\n* **Decentralized:** Each sensor fuses the data and sends it onto the next one\n* **Distributed:** Each sensor fuses data locally and sends it to the next unit\n\n![](/ERC-website-2021/static/fusion_sensors_image2.png)\n\n## On the basis of Composition Level (What?)\n\n* **Competitive Fusion:** When different sensors are meant for the same purpose\n* **Complementary Fusion:** When different sensors are used to look at different scenes to obtain data that couldn’t have been obtained had the been used individually\n* **Coordinated Fusion:** Using multiple sensors to produce a new scene, but looking at the same object. E.g. 3D reconstruction\n\n![](/ERC-website-2021/static/fusion_sensors_image1.png)\n\nFor more details regarding the types of sensor fusion, check [here](https://www.thinkautonomous.ai/blog/?p=9-types-of-sensor-fusion-algorithms \"https://www.thinkautonomous.ai/blog/?p=9-types-of-sensor-fusion-algorithms\").\n\n**Example Calculation Regarding Sensor Fusion**\n\nFor a basic example showing how two measurements can be combined, check [this](https://en.wikipedia.org/wiki/Sensor_fusion#Example_calculations \"https://en.wikipedia.org/wiki/Sensor_fusion#Example_calculations\") section.\n\n# Algorithms on Sensor Fusion\n\n## Based on Sensor Fusion\n\n* The central limit theorem states that when we take a large number of measurements of a parameter, the distribution of their mean tends to a normal distribution, and the mean of the distribution gets closer to the true mean as number of measurements increase.\n* In order to see its relation to sensor fusion, assume we have two different sensors A and B. The more samples we take of their readings, the more closely the distribution of the sample averages will resemble a bell curve and thus approach the set’s true average value.  The closer we approach an accurate average value, the less noise will factor into sensor fusion algorithms.\n* For more information regarding the central limit theorem, check [here](https://en.wikipedia.org/wiki/Central_limit_theorem \"https://en.wikipedia.org/wiki/Central_limit_theorem\").\n\n## Based on Kalman Filter\n\n* A Kalman filter is an algorithm that estimates unknown values by taking data inputs from multiple sources, despite possibly having a high amount of signal noise.\n* It has the advantage of predicting unknown values more accurately by combining measurements than what is obtained on using the measurements individually.\n* The Kalman filter is a recursive algorithm that depends only on the previous state of the system and the current observed sensor data to estimate the current state of the system.\n* For more details regarding the Kalman filter, check [here](https://www.kalmanfilter.net/default.aspx \"https://www.kalmanfilter.net/default.aspx\") or [here](https://www.bzarg.com/p/how-a-kalman-filter-works-in-pictures/ \"https://www.bzarg.com/p/how-a-kalman-filter-works-in-pictures/\").\n\n## Based on Bayesian Networks\n\n* Bayes Rule in probability is the backbone of state update equations used for sensor fusion. Bayesian Networks based on Bayes rule predicts the likelihood that any given measurement is a contributing factor in determining a given parameter.\n* For a detailed study of Bayesian Networks, check [here](https://en.wikipedia.org/wiki/Bayesian_network \"https://en.wikipedia.org/wiki/Bayesian_network\").\n* Some of the algorithms used for Sensor Fusion based on Bayesian networks are [K2](http://web.cs.wpi.edu/\\~cs539/s05/Projects/k2_algorithm.pdf \"http://web.cs.wpi.edu/~cs539/s05/Projects/k2_algorithm.pdf\"), [hill climbing](https://www.geeksforgeeks.org/introduction-hill-climbing-artificial-intelligence/ \"https://www.geeksforgeeks.org/introduction-hill-climbing-artificial-intelligence/\"), [simulated annealing](https://en.wikipedia.org/wiki/Simulated_annealing \"https://en.wikipedia.org/wiki/Simulated_annealing\").\n\n## The Dempster-Shafer Theory\n\n* This theory, called the theory of belief functions or the evidence theory, is a general framework for working with uncertainties and measurements.\n* Dempster–Shafer theory is based on two ideas: obtaining degrees of belief for one question from subjective probabilities for a related question, and Dempster's rule for combining such degrees of belief when they are based on independent items of evidence.\n* For more details on this theory, check [here](https://en.wikipedia.org/wiki/Dempster%E2%80%93Shafer_theory \"https://en.wikipedia.org/wiki/Dempster%E2%80%93Shafer_theory\") or [here](https://www.geeksforgeeks.org/ml-dempster-shafer-theory/ \"https://www.geeksforgeeks.org/ml-dempster-shafer-theory/\").\n\n## Convolutional Neural Networks\n\n* Convolutional neural network based methods can simultaneously process many channels of sensor data. From this fusion of such data, they produce classification results based on image recognition.\n* For a detailed study of CNNs, check [here](https://towardsdatascience.com/a-comprehensive-guide-to-convolutional-neural-networks-the-eli5-way-3bd2b1164a53 \"https://towardsdatascience.com/a-comprehensive-guide-to-convolutional-neural-networks-the-eli5-way-3bd2b1164a53\").\n\n# Conclusion\n\nSensor Fusion is a vast field, with a huge number of algorithms to combine sensor data to obtain measurements. The mathematics behind sensor fusion is often complicated and requires a good understanding of concepts of probability. The goal of this article was to give a brief overview of different types of sensor fusion and to give a bird’s eye view of the various algorithms that can be used for sensor fusion."},"__N_SSG":true},"page":"/blog/[slug]","query":{"slug":"sensor-fusion"},"buildId":"5QJC4znxUt28OyN5o0qMk","assetPrefix":"/ERC-website-2021","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>