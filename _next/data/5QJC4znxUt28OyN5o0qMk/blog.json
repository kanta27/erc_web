{"pageProps":{"allBlogs":[{"frontmatter":{"title":"Arduino","author":"Tejas Amritkar","hero_image":"/ERC-website-2021/static/arduino_cover.jpg","date":"2021-11-24T13:30:00.000Z"},"markdownBody":"Arduino is an **open-source electronics platform** based on easy-to-use hardware and software. Arduino boards are able to read inputs - light on a sensor, a finger on a button, or a Twitter message - and turn it into an output - activating a motor, turning on an LED, publishing something online.\n\n* Open-source Electronics prototyping platform\n* Uses a ‚Äúmicroprocessor‚Äù/‚Äùmicrocontroller‚Äù\n* Programmable in language similar to C\n* Implements many inbuilt functions\n* Multiple sensors available for use\n* Lots of support online - very popular\n\nThere are different Arduino Boards available in the market like Arduino UNO (R3), Arduino Nano, Arduino Mega (R3), etc. We will focus on **Arduino UNO R3** in this tutorial.\n\n# Programming Arduino\n\n* Arduino uses its own IDE (Integrated Development Environment) to write programs.\n* Setting up and programming Arduino : [Arduino](https://www.youtube.com/watch?v=fJWR7dBuc18 \"Arduino Setup\")\n\n# Arduino UNO\n\n## Arduino pins\n\nIf you want detailed info on any of the pins , you can visit here:  \n[robotics backend/arduino-uno-pins](https://roboticsbackend.com/arduino-uno-pins-a-complete-practical-guide/)\n\n![](/ERC-website-2021/static/arduino_image2.png)\n\n1 - USB CONNECTOR  \n2 - POWER JACK  \n3 - GROUND PINS  \n4 - 5V PINS  \n5 - 3.3V PINS  \n6 - ANALOG INPUT PINS  \n7/8 - DIGITAL PINS- out of the 14 Pins, 6 can be used for PWM (denoted by \\~)  \n9 - ANALOG REFERENCE  \n10 - RESET BUTTON  \n11 - POWER LED  \n12 - TX/RX LEDS  \n13 - ATMEGA328P  \n14 - VOLTAGE REGULATOR\n\n## Power Pins\n\n![](/ERC-website-2021/static/arduino_image1.png)\n\n* Vin is the input voltage to the board when it‚Äôs using an external power source (as opposed to 5 volts from the USB connection or other regulated power source from the power jack)\n* You can supply voltage through this pin(from external circuitry), or, if supplying voltage via the power jack, access it through this pin.\n* This is how you power the board when it‚Äôs not plugged into a USB port for power. Can accept voltages between 7-12V(But the voltage is regulated to a maximum of 5V)\n\n## LEDs\n\n* **Pin 13 LED:** The only actuator built into the board. Useful for debugging, since the LED is in-built and hence reliable in terms of connections.\n* **Power LED:** Indicates that the board is receiving power. Useful for debugging.\n* **Reset button:** Resets the ATmega microcontroller.\n* **TX and RX LEDs:** Indicate communication(send/receive) between the board and the computer. Flicker rapidly during sketch upload as well as during serial communication. Useful for debugging.\n\n## USB Port\n\n* Used for the board, and most importantly, uploading your sketches to the board.\n* Also used for communicating with the sketch (via Serial.println() etc).\n\n## Digital Pins\n\n![](/ERC-website-2021/static/arduino_image8.png)  \nDigital **Input/Output** pins(0,1 are serial in/out) are numbered from 2-13  \nHigh(5V) or Low(0V)  \nDigital reading pins ( for input V < 0.8 => low; V > 2 => high)\n\n**Arduino LED:**\n\nExample 1:  \nLet‚Äôs make the LED blink, which means that we are going to :\n\n1. Power in the LED\n2. Wait\n3. Power off the LED\n4. Wait\n5. Go back to 1\n\nSee the code here : [Example1](https://github.com/Tejas2910/Getting-started-with-Arduino/blob/main/README.md#example-1)\n\n![](/ERC-website-2021/static/arduino_image3.png)\n\n**digitalWrite(Pin_no, HIGH/LOW);**  \nHIGH sets the pin to give a 5V (high) output while a low sets the pin to give a 0V output.  \nOnly to assign the value to the output pins.\n\n**digitalRead(Pin_no);**  \nGives the reading of the digital input pin as a high or a low.\n\n## PWM Pins\n\nPWM enabled pins(3,5,6,9,10,11) can also be used as Analog **Outputs** (represented by \\~)  \nanalogWrite(LED_PIN, n); **n** can take values from **0 to 255**.\n\nIn the Example1 replacing line digitalWrite(LED_PIN, HIGH); with analogWrite(LED_PIN, 102); will cause 102/255 ie. 40% of maximum voltage( 5V) across circuit.  \n(can be used to change the brightness of the LED in this example)\n\nExample 2:  \nLet‚Äôs make the LED fade in (which means the brightness will slowly increase until the max), and then fade out (brightness will slowly decrease), so we can create a nice effect with the LED.  \nSee the code here : [Example2](https://github.com/Tejas2910/Getting-started-with-Arduino/blob/main/README.md#example-2)\n\n## Analog Pins\n\n![](/ERC-website-2021/static/arduino_image14.png)\n\n\\**analogRead(Pin_no);  \n\\**Reads the input from the analog pins marked as A0,A1...A5 on the arduino board. This reading is a 10 bit value (0-1023).\n\nLet's say Arduino is reading 2V.  \n2V is 40% of 5V (Vcc). In your Arduino program, you will then get the value 409 ( 40% of 1024 ). From this value, you can easily reverse the computation and get the information about the voltage that was applied.\n\n## Serial Communication\n\nSerial is used for communication between the Arduino board and a computer or other devices. All Arduino boards have at least one serial port (also known as a UART or USART). It communicates on digital pins 0 (RX) and 1 (TX) as well as with the computer via USB. Thus, if you use these functions, you cannot also use pins 0 and 1 for digital input or output.\n\n\\**Arduino Serial port and Print Commands:  \n\\**See the example here : [Example 3](https://github.com/Tejas2910/Getting-started-with-Arduino/blob/main/README.md#example-3)  \nOpen the Serial monitor ( on top right corner)\n\nSerial.begin(baud_rate);  \nSets the data rate in bits per second (baud) for serial data transmission. Settable to 300, 600, 1200, 2400, 4800, 9600, 14400, 19200, 28800, 38400, 57600 or 115200 baud rate defined here and that selected on the serial monitor should be the same.\n\nSerial.end();  \nDisables serial communication, allowing the RX and TX pins to be used for general input and output.\n\nif(Serial);  \nIndicates if the specified Serial port is ready.\n\nSerial.available();  \nGet the number of bytes (characters) available for reading from the serial port.\n\nSerial.read();  \nReads incoming data\n\nSerial.print(j);  \nprint on the same line\n\nThere are many serial functions that have not been covered in the previous segment, but they are important for some specific uses.  \n[https://www.arduino.cc/en/reference/serial](https://www.arduino.cc/en/reference/serial \"https://www.arduino.cc/en/reference/serial\")\n\n\\**Reading data from serial monitor :  \n\\**Example 4 : Tell the Arduino how many times you want to blink LED  \nSee the code here: [Example 4](https://github.com/Tejas2910/Getting-started-with-Arduino/blob/main/README.md#exmaple-4)\n\n## Interrupt Pins\n\nPurpose - Stop the continuous progress of an activity or process.  \nInterrupts triggers a function inside the Arduino code. This stops the main execution of your program. After the triggered function is done, the **main execution resumes**.\n\n**Digital Pins 2, 3** are Interrupts pins.\n\nBefore going through the example, lets introduce the **push button**. You should notice which pins are internally connected and which are not.\n\n![](/ERC-website-2021/static/arduino_image4.jpg)\n\n**Example 5:** The goal of the Example is to change the state of a LED when the the user presses a push button.\n\nPart 1 : Arduino code without interrupts  \nSee the code here : [Example5_Part1](https://github.com/Tejas2910/Getting-started-with-Arduino/blob/main/README.md#part-1)\n\nPart 2 : Arduino code with Interrupts  \nSee the code here : [Example5_Part2](https://github.com/Tejas2910/Getting-started-with-Arduino/blob/main/README.md#part-2)\n\n![](/ERC-website-2021/static/arduino_image6.png)\n\n**Note** : Make the interrupt function as fast as possible, because it stops the main execution of your program.\n\n**Volatile Variables :**\n\nIf you modify a variable inside an interrupt, then you should declare this variable as volatile.\n\nThe compiler does many things to optimize the code and the speed of the program. This is a good thing, but here we need to tell it to ‚Äúslow down‚Äù on optimization.\n\nFor example, if the compiler sees a variable declaration, but the variable is not used anywhere in the code (except from interrupts), it may remove that variable. With a volatile variable you‚Äôre sure that it won‚Äôt happen, the variable will be stored anyway.\n\nNote that only variables that are used inside and outside an interrupt should be declared as volatile. You don‚Äôt want to unnecessarily slow down your code.\n\nIf you want to get deeper into Interrupt pins, check this out : [arduino-interrupts](https://roboticsbackend.com/arduino-interrupts/)\n\n# Peripherals\n\nArduino supports multiple peripherals like:\n\n* Ultrasonic Sensor\n* LCD\n* Bluetooth\n* Pressure Sensor\n* Accelerometer/Gyrometer\n* RTC module\n* SD card\n* LDR sensor\n* Temperature sensor\n\n## Ultrasonic Sensor\n\n* This sensor sends out pulses from T, which bounce off from the object and R receives them.\n* When the receiver gets the U.S. pulses, it generates a high signal. We get the time difference between the pulses which is used to calculate the distance\n* The speed of sound is approximately 341 meters (1100 feet) per second in air.\n* **Distance = (Time x Speed of Sound)/2**\n\n![](/ERC-website-2021/static/arduino_image15.png)\n\nUseful Function:  \npulseIn(Pin_no, HIGH);  \nGives the time in milliseconds from the time this command is initiated until Pin_no gives a HIGH pulse.\n\n**Sample:**\n\n* Initialise variables before setup()\n* Sets the data rate of data received from the board using Serial.begin() and sets the trig pin to OUTPUT and echo pin to INPUT.\n* First three lines of loop() send out a trigger pulse on the trig pin to cause the sensor to emit an ultrasound pulse.\n* pulseIn(echo, HIGH) records the time after which the echo pin receives a HIGH pulse.\n* Data is converted into distance in cm and printed to the Serial monitor.\n\n**Exercise:**\n\nHow to measure distance using Ultrasonic sensor **HC-SR04** - [Link](https://create.arduino.cc/projecthub/knackminds/how-to-measure-distance-using-ultrasonic-sensor-hc-sr04-a-b9f7f8) (Error in pin mapping)  \nNote:  \nTRIG connection of the sensor attached to digital **pin 12**  \nECHO connection of the sensor attached to digital **pin 13**)\n\n## LCD\n\nWhy is the LCD used?  \nTo display certain information or data on the screen. They are useful for debugging when you cannot use a laptop or serial monitor.\n\n![](/ERC-website-2021/static/arduino_image9.png)![](/ERC-website-2021/static/arduino_image13.png)\n\n**Functions:**\n\n* lcd.begin(16,2): This declares the size of LCD\n* lcd.clear(): Clears the LCD\n* lcd.setCursor(0,0): Moves the cursor to (0,0) of the array\n* lcd.print(‚Äúhello world‚Äù): Prints whatever is in the bracket\n\n**Exercise:**\n\nWrite code to display the distance directly onto the LCD  \nFor more information visit : [Liquid_Crystal_Library](https://www.arduino.cc/en/Reference/LiquidCrystal)\n\n## Infrared Sensor\n\n![](/ERC-website-2021/static/arduino_image10.png)\n\n* I.R. sensor is used as a proximity sensor or collision sensor (not exact distance).\n* TX which emits IR light continuously.\n* So, when an object is near the sensor light is reflected into the RX which creates a voltage difference.\n* The generation of this voltage difference depends on the intensity of IR light received by the RX\n* **Note: You cannot use IR sensors outdoors or in bright lights because the IR light of the sun or from the bulb interacts with the RX. Use US sensors instead.**\n\n  ![](/ERC-website-2021/static/arduino_image16.png)\n\n\\**IR Sensor People Counter  \n\\**To make a device which counts the number of people entered, excited and present in the room using an IR sensor.\n\n![](/ERC-website-2021/static/arduino_image12.png)![](/ERC-website-2021/static/arduino_image7.png)\n\n**Example**\n\n* For an Arduino UNO we can only send one byte at a time and hence we will communicate between the two arduinos using characters ‚ÄúH‚Äù and ‚ÄúL‚Äù. (We can do this using numbers as well)\n* One Arduino will serve as a sender while the other will be a receiver. The communication will take place through the set of Serial() functions.\n\n## Bluetooth Module\n\n![](/ERC-website-2021/static/arduino_image5.jpg)\n\nHere is our Bluetooth Module with its Pinout.  \nThe Bluetooth Module will communicate with Arduino via Tx / Rx Pins (Pin1/Pin0) present on Arduino,as we used second Arduino in above communication.  \nPs:We Only Need **Vcc,Gnd,Tx,Rx** Pins For Such Communication.\n\n![](/ERC-website-2021/static/arduino_image11.png)\n\nArduino bluetooth basic tutorial: [working on bluetooth module](https://create.arduino.cc/projecthub/mayooghgirish/arduino-bluetooth-basic-tutorial-d8b737)\n\n# Arduino Communication Protocols\n\nThree Protocols for device communication :\n\n1. **UART** - Universal Asynchronous Receiver/Transmitter\n2. **SPI** - Serial Peripheral Interface\n3. **I2C** - Inter-integrated circuit\n\nDetails can be seen here : [Arduino-communication-protocols](https://www.deviceplus.com/arduino/arduino-communication-protocols-tutorial/)","slug":"arduino"},{"frontmatter":{"title":"Controls Theory","author":"Pranav Malpure","hero_image":"/ERC-website-2021/static/controls_theory_cover.jpg","date":"2021-11-25T13:50:00.000Z"},"markdownBody":"Control theory is a branch of mathematics and engineering, which defines the conditions needed for a system to maintain a controlled output in the face of input variation. In simple terms, we seek to stabilize our system through some control theory concepts when many factors can destabilize it. At the end of reading this article, you can expect to have an overview of control theory with some basic knowledge of PID control.\n\nTo understand this, first, let us know a few terms:\n\n1\\. **Input:** The set of instructions given to the system\n\n2\\. **Output:** Consists of a group of variables that describe the state of the system. Usually represented by ùë•\n\n3\\. **Control System:** The entire system, which includes a _controller_, _plant_, and _sensors_, is collectively known as a control system. The _plant_ is a part that is controlled. The _controller_ provides control commands to the plant. _Sensors_ measure the state of the system. See the flow diagram for reference:\n\n![](/ERC-website-2021/static/image9.png)\n\nTo put these terms into an application, let‚Äôs take the example of a person driving a car. (Pause here and try to identify what could be the input, output, and control system in this example.) So, in this case, the _input_ could be instructions given to the driver by his brain. The driver will be the _controller_, which controls the car using the instructions received. The vehicle will be the _plant_; sensors would be the speedometer, driver‚Äôs eyes to see the traffic, ears to listen to any horn, etc. The _output_ could be the velocity of the car, current traffic conditions on the road, etc.\n\nNow that you understand basic terms let's move on to classifying control systems.\n\nWe classify control systems on various bases, but the most prominent ones are:\n\n## 1. Based on feedback (output)\n\n* **Open-loop control system** - In this type of system, the input given to the controller is independent of the output. In the above car example, we can see that if the driver doesn‚Äôt pay heed to the current state of the system(the output) and drives it just based on some pre-learned instructions, then this system would be an open loop, as there are no changes made to the input depending on the output. As you must have noticed, this type of system is problematic as it cannot account for any uncertainties.\n* **Closed-loop control system** - Here, the input commands are based on the output received. For example, when a car stops in front, the driver‚Äôs input will change, and they will apply brakes.\n\n## 2. Based on energy expenditure\n\n* **Active** - In this type, a certain amount of energy is required to implement the control commands. For example, to accelerate the car, it will consume fuel.\n* **Passive** - This system involves minimal energy expenditure to implement the input into the system. For example, if the car goes downhill, it can be controlled by just applying the brakes.\n\nSince we now have an overview of control theory, let us bring some maths into the picture, let the input function be _u(t)_ and output function be _x(t)_.\n\nWondering what use maths is of? Read on...\n\n# Control Law\n\nVarious types of systems have different anomalies present in them. In many cases, we can express the output and correction to the input to control the system through some mathematical relation. This relation is known as a _control law_. So, a _control law_ is a mathematical law that relates output and input, along with other control command parameters or measurable properties of the state.\n\nExample:   \t\tu(t) = -K(x(t) - x0)\n\nThere are various control laws, such as _Linear Quadratic Regulator_ (the above example is an LQR), _PID control_, etc., which may be helpful in different scenarios. One such law is PID which is widely used even in industries because it is simple and works for almost every case.\n\n# Proportional-Integral-Derivative (PID)\n\nThe control law for PID is:\n\n![](/ERC-website-2021/static/image5.png)\n\nDon‚Äôt get overwhelmed with the equation! It‚Äôs pretty simple when you understand it.\n\nLet us understand what each term is:\n\n1\\. **Kp** is the proportional coefficient/weight\n\n2\\. **Kd** is the derivative coefficient/weight\n\n3\\. **Ki** is the integral coefficient/weight\n\n4\\. **Ti** is the integral time constant\n\n5\\. **Td** is the derivative time constant\n\nHere, _e(t)_ is the error between the desired and the actual state.\n\nThis law has three parts: **proportional**, **integral** and **derivative** parts; each one of them has its own importance.\n\n**Proportional(P)**\n\nIn this the input is linearly proportional to the error, which means that the error is just scaled using the constant **Kp**.\n\n**Integral(I)**\n\nThe integral of error over time is scaled with a constant **Ki**.\n\n**Derivative(D)**\n\nHere, the derivative of the error is scaled and multiplied by the constant **Kd**.\n\nEach of the above components aims to correct different causes of the error, and together these three combine to give us the best desired output.\n\nLet‚Äôs understand the use of all the above three components using an example of a self-driving car. We have to design the controls of the vehicle. The car is supposed to move on a given marked line. Let's start with our analysis:\n\nThe input given to the car is to turn its steering wheel to left or right by a fixed angle, as shown below.\n\n![](/ERC-website-2021/static/image8.png)\n\nBut there is a problem with this; we are instructing to turn the steering wheel by the same angle even if the car is slightly offset. This will make the vehicle constantly oscillate around the line, and the ride will be jerky, making it uncomfortable for the passengers.\n\n![](/ERC-website-2021/static/image3.png)\n\nSo what can be done to solve this? We need to turn the steering wheel in proportion to the error, i.e., its offset from the line. This is where the P part comes into play. Notice what will happen if we give the input as: _u(t) = Kp e(t)_\n\n![](/ERC-website-2021/static/image2.png)\n\nHere we turn the steering by a smaller angle if the error is small and the problem is solved. But there is a problem with this too! This control works well with low offset, but it may lead to a situation like below when the error is high.\n\n![](/ERC-website-2021/static/image7.png)\n\nSince the initial angle is high, the steering angle is relatively high, but as a result, it leads to the car closing in on the line much quicker, even quicker than what the car can account for by decreasing the angle; hence it will overshoot. And again, the same story will repeat from the other side, leading to oscillations.\n\nSo how do we solve this? Here‚Äôs where the D part comes in handy. The input is modified as:  _u(t) = Kp e(t)  +  Kd e'(t)_\n\nThe added term takes into account the rate of change of error. So if the error is decreasing rapidly, _e'(t)_ will be highly negative. So when the error is enormous, the proportional part will be high, but as the car starts to steer, the derivative term will increase in the negative direction, avoiding the car to turn too quickly. So we will get an ideal situation as below:\n\n![](/ERC-website-2021/static/image4.png)\n\nThis is collectively known as **PD control**.\n\nWait! There is still a problem. Only P and D can lead to an error known as steady-state error. Take the following case: Let's say the car is driving at a small constant error parallel to the marked line (purple).\n\n![](/ERC-website-2021/static/image1.png)\n\nHow will the P and D act in this case? Since the error is small, the proportional part will steer through a slight angle, but as soon as it starts turning, _e'(t)_ will become negative and nullify the P term; hence the car will continue with a constant error (steady-state error).\n\nThe I part helps to account for this error. The input function now becomes:\n\n`u(t) = Kp e(t) + Kd e'(t) + Ki ‚à´e(t).dt`\n\nIntegral term adds the net error till the current time and tries to make it zero.\n\nSo here, the integral part will add up the steady-state error and slowly reduce the error.\n\n![](/ERC-website-2021/static/image6.png)\n\nAs we can see from the above image, the initial small steady-state error is quickly reduced to zero using the _Integral_ term.\n\nThis completes our analysis of the **PID** control law. Note that the constants Kp, Kd  & Ki are tuned ample times to get the perfect combination of the three, such that none of them overshadows the other terms, and we get our desired output.\n\nSo we come to an end of this short introduction to Control Theory. It is a math-heavy topic, and this was quite a superficial picture. For those interested to learn further and reading more about Control theory, you may go through the Controls Theory Bootcamp conducted by ERC. It involves a mathematical approach which is needed for a deeper understanding of the topic. The link for it is [here](https://github.com/erciitb/tss-controls-theory \"here\").","slug":"controls-theory"},{"frontmatter":{"title":"Motors and Motor Drivers","author":"Sourabh Hanje","hero_image":"/ERC-website-2021/static/motors_cover.jpg","date":"2021-11-28T12:30:00.000Z"},"markdownBody":"A motor is a device that changes a form of energy into mechanical energy to produce motion. Electric motors convert electrical energy into mechanical energy.\n\nIn Electronics and Robotics applications, motors are used as actuators.  \nAn actuator is a device that produces a motion by converting energy and signals going into the system. The motion it produces can be either rotary or linear.  \nThe component that motors actuate can be anything such as it wheels, legs, tracks, arms, fingers, sensor turrets, camera, or weapon systems etc.\n\nBased on the project requirements, we have many types of motors at our Disposal. Below are the most used ones:\n\n* Brushed DC motor\n* Brushless DC motor\n* Geared DC motor\n* Servo motor\n* Stepper motor\n* DC linear actuator\n\n# Brushed DC Motor\n\n![](/ERC-website-2021/static/motors_image1.jpg)![](/ERC-website-2021/static/motors_image3.jpg)\n\nA brushed DC motor is one which uses two brushes to conduct current from source to armature. There are several variations on the brush DC motor, but permanent magnet DC motor (PMDC) is used extensively in robotics. Brushed DC motors are widely used in applications ranging from toys to push-button adjustable car seats. Brushed DC (BDC) motors are inexpensive, easy to drive, and are readily available in all sizes and shapes.\n\nThe brush DC Motor consists of six different components: the axle, armature/rotor, commutator, stator, magnets, and brushes. A Brush DC Motor consists of two magnets facing the same direction, that surrounding two coils of wire that reside in the middle of the Brush DC Motor, around a rotor. The coils are positioned to face the magnets, causing electricity to flow to them. This generates a magnetic field, which ultimately pushes the coils away from the magnets they are facing, and causes the rotor to turn.\n\nThe Brush DC Motor has two terminals; when voltage is applied across the two terminals, a proportional speed is outputted to the shaft of the Brush DC Motor. A Brush DC Motor consists of two pieces: the stator which includes the housing, permanent magnets, and brushes, and the rotor, which consists of the output shaft, windings and commutator. The Brush DC Motor stator is stationary, while the rotor rotates with respect to the Brush DC Motor stator.The stator generates a stationary magnetic field that surrounds the rotor. The rotor, also called the armature, is made up of one or more windings. When these windings are energized they produce a magnetic field. The magnetic poles of this rotor field will be attracted to the opposite poles generated by the stator, causing the rotor to turn. As the motor turns, the windings are constantly being energized in a different sequence so that the magnetic poles generated by the rotor do not overrun the poles generated in the stator. This switching of the field in the rotor windings is called commutation.\n\nUnlike other electric motor types (i.e., brushless DC, AC induction), BDC motors do not require a controller to switch current in the motor windings. Instead, the commutation of the windings of a BDC motor is done mechanically. A segmented copper sleeve, called a commutator, resides on the axle of a BDC motor. As the motor turns, carbon brushes slide over the commutator, coming in contact with different segments of the commutator. The segments are attached to different rotor windings, therefore, a dynamic magnetic field is generated inside the motor when a voltage is applied across the brushes of the motor. It is important to note that the brushes and commutator are the parts of a BDC motor that are most prone to wear because they are sliding past each other.\n\n**Applications:**\n\n* Toys\n* RC Servos\n* Gear Motors\n\n**Advantages:**\n\n* Inexpensive\n* Lightweight\n* Reasonably Efficient\n* Good low-speed torque\n\n**Limitations:**\n\n* In addition to the audible whine from the commutator brushes, these motors create a lot of electrical noise which can find its way back into other circuitry and cause problems.\n\n# Geared DC Motor\n\n![](/ERC-website-2021/static/motors_image2.jpg)\n\nGeared DC motors can be defined as an extension of DC motor which already had its Insight details demystified before. A geared DC Motor has a gear assembly attached to the motor. The speed of motor is counted in terms of rotations of the shaft per minute and is termed as RPM .The gear assembly helps in increasing the torque and reducing the speed. Using the correct combination of gears in a gear motor, its speed can be reduced to any desirable figure. This concept where gears reduce the speed of the vehicle but increase its torque is known as gear reduction. This Insight will explore all the minor and major details that make the gear head and hence the working of geared DC motor.\n\n**Working of the DC Geared Motor**\n\n* The DC motor works over a fair range of voltage. The higher the input voltage more is the RPM (rotations per minute) of the motor. For example, if the motor works in the range of 6-12V, it will have the least RPM at 6V and maximum at 12 V. In terms of voltage, we can put the equation as: RPM= K1 * V, where, K1= induced voltage constant V=voltage applied.\n* The working of the gears is very interesting to know. It can be explained by the principle of conservation of angular momentum. The gear having smaller radius will cover more RPM than the one with larger radius. However, the larger gear will give more torque to the smaller gear than vice versa. The comparison of angular velocity between input gear (the one that transfers energy) to output gear gives the gear ratio. When multiple gears are connected together, conservation of energy is also followed. The direction in which the other gear rotates is always the opposite of the gear adjacent to it. In any DC motor, RPM and torque are inversely proportional. Hence the gear having more torque will provide a lesser RPM and converse. In a geared DC motor, the concept of pulse width modulation is applied.\n\nFor example, an unloaded DC motor might spin at 12000 rpm and provide 0.1 kg-cm of torque. A 225:1 geardown is added to proportionally reduce the speed and increase the torque: 12000 rpm / 225 = 53.3 rpm and 0.1 x 225 = 22.5 kg-cm. The motor will now be able to move significantly more weight at a more reasonable speed.\n\nIn a geared DC motor, the gear connecting the motor and the gear head is quite small, hence it transfers more speed to the larger teeth part of the gear head and makes it rotate. The larger part of the gear further turns the smaller duplex part. The small duplex part receives the torque but not the speed from its predecessor which it transfers to larger part of other gear and so on. The third gear‚Äôs duplex part has more teeth than others and hence it transfers more torque to the gear that is connected to the shaft.\n\n**Applications:**\n\n* Robot Drive Trains\n* Radio Control Vehicles\n* Cordless Tools\n\n**Advantages:**\n\n* Speed Reduction - Many DC motors simply run too fast to be useful in direct-drive applications.\n* Increased Torque - A lot of work can be coaxed from a relatively small motor if fitted with a suitable gear train.\n\n**Limitations:**\n\n* This is especially a problem with low-cost plastic gear trains used with low-voltage motors.\n* The extra resistance can make these gear-trains balky at low speeds.","slug":"motors-and-motor-drivers"},{"frontmatter":{"title":"PCB Designing with Autodesk Eagle","author":"Kaushal Jadhav","hero_image":"/ERC-website-2021/static/pcb_cover.png","date":"2021-11-24T12:30:00.000Z"},"markdownBody":"PCB is an acronym for Printed Circuit Board. It is a board with many lines and pads that connects various points together using conductive pathways. Traces are etched on copper sheets to make these pathways and the sheets are then laminated on a non-conductive substrate board.\n\n![](/ERC-website-2021/static/pcb_image2.jpg)\n\n# Why are PCBs so important?\n\nPCBs were invented in 1936.  \nLife before 1936:\n\n![](/ERC-website-2021/static/pcb_image1.jpg)  \nImagine you are an electrical engineer tasked with debugging this!  \nAnd don‚Äôt even get me started on maintaining such circuits\n\n# Composition and structure\n\nThe composition of a PCB is basically like a layered cake\n\n![](/ERC-website-2021/static/pcb_image3.jpg)\n\n**Silkscreen:** The silkscreen adds letters, numbers, and symbols to the PCB that allow for easier readability.\n\n**Substrate (FR4):** The base material, or substrate, is usually fiberglass. This solid core gives the PCB its rigidity and thickness but keeps it flexible at the same time.\n\n**Soldermask:** This layer gives the PCB its distinctive green colour and is overlaid onto the copper layer to insulate the copper traces from accidental contact with other metal, solder, or conductive bits.\n\n**Copper:** Copper is laminated on both sides of the board with heat and adhesive. It electrically connects the electronic components and signals.\n\n# Understanding PCB terminology and basic terms\n\nNow that we‚Äôve got an idea of what a PCB structure is, let‚Äôs learn to read a PCB.\n\nPCBs involve a lot of overwhelming terminology and jargon. The good news is you don‚Äôt need to understand every bit of it. A basic understanding will suffice to start with.\n\nHere‚Äôs a link to a doc referring to the same:\n\n# Autodesk EAGLE\n\nThere are many PCB CAD softwares out there. But we will be covering EAGLE in this tutorial.\n\n_So what‚Äôs so special about EAGLE?_\n\nEAGLE is lightweight (50-200MB of disk space), free for students, has cross-platform support and most importantly has a great active community.\n\n**_Download, License and Install:_**\n\nEAGLE is free to [download](https://www.autodesk.com/products/eagle/free-download) and install with a student‚Äôs license. Create/Log-on to your Autodesk account with your college ID and grab the version that matches your operating system.\n\nEAGLE installs just like most programs. The download is an executable file; open it and follow the installation instructions. You can find the download link on A\n\n**_Libraries:_**\n\nIncluded with EAGLE is an impressive list of part libraries. These hundreds of libraries might be very useful for high end industrial PCB designing; but they end up becoming very overwhelming for us beginners.\n\nThe [SparkFun EAGLE libraries](https://github.com/sparkfun/SparkFun-Eagle-Libraries) are a good starting point. They are easy to understand and are also frequently updated.\n\nAfter downloading, navigate to Documents\\\\EAGLE\\\\libraries and paste the folder to add them to your resources.\n\n**_Creating your first project in EAGLE:_**\n\nAlright now, finally we can boot-up EAGLE and get started!\n\nWe'll start by making a new **project folder** for our design. In the control panel, under the \"Projects\" tree, right click on the directory where you want the project to live and select **\"New Project\"** and give it a nice descriptive name.\n\nThe project folder will house both our schematic and board design files.\n\nThese are the yin and the yang of EAGLE. They should be used together to create the finished product that is a functional PCB design.\n\n# The Schematic editor:\n\nTo add a schematic to a project folder, right-click the folder, hover over **\"New\"** and select **\"Schematic\"**. A new blank window will immediately pop-up.\n\nWelcome to the schematic editor!\n\nSchematic designing in EAGLE is like adding a few parts, wiring them, then adding some more and then wiring them again.\n\nAdding Parts to a Schematic\n\nThe ADD tool ![](/ERC-website-2021/static/pcb_image5.png) opens up a library navigator, where you can expand specific libraries and look at the parts it holds. The most important functionality of the ADD tool is probably the search bar.\n\nThe search is very literal, so don't misspell stuff! A very crucial tip is the use of asterisks (*) before and after every component. This makes the search more lenient.\n\nFor example, if you search for _atmega328_ you should find a single part in the library, but if you search _atmega328_ (note asterisks before and after), you'll discover two more versions of the IC (because they're actually named \"ATMEGA328_P_\").\n\nAdd all the components, connectors and the power inputs using this tool.\n\nAfter placing the parts, if you need to move them around, use the MOVE tool -- ![](/ERC-website-2021/static/pcb_image4.png)\n\n**_Wiring Up the Schematic:_**\n\nThere's one major caveat here before we start: even though we're wiring parts on the schematic, we not going to use the WIRE tool --![](/ERC-website-2021/static/pcb_image7.png)-- to connect them together. Instead, we'll use the NET tool -- ![](/ERC-website-2021/static/pcb_image6.png). The WIRE tool would be better-named as a line-drawing tool, NET does a better job of connecting components.\n\nHover over the very end of a pin (as close as possible, zoom in if you have to), and left-click once to start a wire. Now a green line should be following your mouse cursor around. To terminate the net, left-click on either another pin or a net. Start by routing the easiest and closest ones first.\n\nSuppose you encounter a pin that is to be connected to a component all the way on the other side. You could do it, it would work, but it'd be really ugly. Instead, we use the NAME tool -- ![](/ERC-website-2021/static/pcb_image10.png) and the LABEL tool -- ![](/ERC-website-2021/static/pcb_image8.png).\n\nBegin by starting a net at a pin, just as you've been doing. Terminate the net by left-clicking a few grid-lengths over to the right of the pin. Then, instead of routing to another pin, just hit ESC to finish the route. With the NAME tool selected now click on the net and give it a short descriptive name. In the same way, create an unfinished net connected to the component and give it the same name as before. This should result in a warning dialog, asking you if you want to connect this net to all of the other nets with the same name. Thanks for looking out for us EAGLE, but in this case _Yes_ we do want to connect them.\n\nAfter naming a net, you should use the LABEL tool -- ![](/ERC-website-2021/static/pcb_image8.png) -- to add a text label for better readability.\n\nSome other useful tools:\n\n* The GROUP tool -- ![](/ERC-website-2021/static/pcb_image11.png)\n\nIn order to perform any action on a group, you have to select the tool, then **hold down CTRL** and **right-click the group**. After you CTRL+right-click, the tool will operate on the group just as it does a single component.\n\n* The SHOW tool -- ![](/ERC-website-2021/static/pcb_image13.png)\n\nIf you use SHOW on a net, every pin it's connected to should light up verifying that pins across your schematic are connected correctly.\n\n* COPY -- ![](/ERC-website-2021/static/pcb_image14.png)-- and PASTE -- ![](/ERC-website-2021/static/pcb_image15.png) -- tools\n\nEAGLE's Copy and Paste tools don't work exactly like other copy/paste tools you may have encountered before. Copy actually performs both a copy and paste when it's used while Paste can only be used to paste a **group** that has previously been copied to your clipboard.\n\n# The Board Editor:\n\nEAGLE's board designer is where a good portion of the magic happens.\n\nWhen you are done with the basic schematic of your design, simply click on the _Generate/Switch to Board_ command -- ![](/ERC-website-2021/static/pcb_image16.png). A Board Editor window will open with all your parts stacked on one another connected with golden air-wires ready to be placed and routed.\n\nBefore getting started with laying down the components, it is imperative to first adjust the grid. Click on the GRID icon -- ![](/ERC-website-2021/static/pcb_image17.png) and adjust the size. Generally, a 0.05\" grid, and 0.005\" alternate grid is a good size but do check it according to your specific requirements.\n\n**_Laying the Board:_**\n\nUse the MOVE tool ![](/ERC-website-2021/static/pcb_image4.png) to arrange your parts, right-clicking will rotate the part. The way you arrange your parts has a huge impact on how easy or hard the next step will be.\n\nHere are a few things to keep in mind:\n\n* **Don‚Äôt overlap parts**: All parts need to have some clearance between them to ensure the signals don‚Äôt short circuit.\n* **Minimize intersecting air-wires**: Limiting criss-crossing air-wires will make routing _much_ easier in the long run.\n* **Part placement requirements**: Some parts may require special considerations like the power connector will always be placed on the edge of the board.\n* **Cost vs. Effort: The tighter your board is the cheaper it is, but it also makes routing that much harder.**\n\n**_Routing the Board_**\n\nRouting is probably the most fun part of PCB designing. It‚Äôs almost like solving a puzzle.\n\nClick on the ROUTE tool and route away! On a 2-layer board, you can route the wires in either red or blue colour. Each colour specifying a different copper layer that you can switch using your middle-mouse button. You can also change the Bend style and Width of your routes. Usually, you will want to keep it 45 degrees and 0.01‚Äù.\n\n![](/ERC-website-2021/static/pcb_image18.png)\n\nAnother important thing to remember while routing is to avoid overlaps of any sort. If traces do cross each other on opposite sides of the board, it's perfectly. That's why there are two layers!\n\n**_Vias:_**\n\nVias are a cool workaround to avoid overlaps. It allows you to travel between the red and blue layers. But don‚Äôt get carried away because more vias mean more money.\n\n**_The Alternate grid:_**\n\nIf you need more precision, hold down the ALT key to access the alternate grid. But do make sure to keep enough route clearance. A good rule of thumb is to keep enough space between two routes to run another one between them.\n\n**_The Auto-Router:_**\n\nCheater! If you are short on time or having trouble routing the PCB yourself you can use EAGLE‚Äôs Autorouter ![](/ERC-website-2021/static/pcb_image19.png). It gets the job done but has no regard for your cost constraints.\n\n**_Checking for Errors:_**\n\nThere are two checks to perform before we can package the PCB and send it to the fabrication house.\n\n1. **Ratsnest:**\n\nThe RATSNEST tool ![](/ERC-website-2021/static/pcb_image20.png) checks if you have routed everything and say the sweetest words a PCB designer can ever hear: ![](/ERC-website-2021/static/pcb_image9.png)\n\n1. **Design Rule Check (DRC)**\n\nThe DRC ![](/ERC-website-2021/static/pcb_image12.png) can provide all sorts of errors like if a trace is too close to either another trace or a via, or two different signal traces are overlapping each other or even if a trace, pad, or via is intersecting with (or too close to) a dimension line.","slug":"pcb-designing-with-autodesk-eagle"},{"frontmatter":{"title":"Rviz","author":"Jacob Thomas Sony","hero_image":"/ERC-website-2021/static/rviz_cover.jpg","date":"2021-10-17T12:30:00.000Z"},"markdownBody":"Rviz is a **3D visualizer** for **ROS** that lets us view a lot about the **sensing**, **processing** and **state** of a robot.  \nThis make the development of robots easier and also enables us to debug more efficiently (better than looking at numbers on a terminal :P)\n\n## Rviz vs Gazebo\n\nRviz is a **visualizer** i.e it shows what the robot perceives is happening while Gazebo is a **simulator** i.e. it shows what is actually happening.  \nConsider the scenario in which we do not have physical hardware-based robots. In that case we would use a simulator like Gazebo to know what would actually happen and the data from the sensors can be visualized in a visualization tool like Rviz. In case we have physical robots, then the data from the sensors can still be visualized in Rviz, but we do not need a simulator necessarily.\n\nTo get started with the installation and some beginner friendly example in Rviz, you may follow [_this link_](https://colab.research.google.com/drive/1FY9xGYzi_hh2C5L747Im7VsMwvI352MK#scrollTo=mKydxDSjsMCr).","slug":"rviz"},{"frontmatter":{"title":"Sensor Fusion","author":"Govind Saju","hero_image":"/ERC-website-2021/static/fusion_sensors_cover.jpg","date":"2021-11-24T12:30:00.000Z"},"markdownBody":"Sensor Fusion refers to the process of combining measurements from different sources to ensure that resulting information has lesser uncertainty as compared to any of the individual measurements. As an example, we can calculate depth information from 2-D images by combining data from 2 cameras at slightly different locations.\n\nThe different sources for the information we obtain need not be identical. There are three types of fusion methods:\n\n* **Direct Fusion:** Fusion of data from a set of either heterogenous or homogenous set of sensors along with past history of sensor data\n* **Indirect Fusion:** Along with sources in direct fusion, we also use sources like a priori knowledge about the information, and human input.\n* **Combination of both:** We can also obtain information by combining the outputs of the above 2 methods of fusion\n\n# Classification of Sensor Fusion Algorithms\n\nSensor Fusion algorithms can be classified on different parameters:\n\n## On the basis of Abstraction Level (When?)\n\n* **Low Level Fusion:** Fusing the raw data coming in from different sensors\n* **Mid Level Fusion:** Fusing the detections from each sensor\n* **High Level Fusion:** Fusing the trajectories (predictions) of each sensor\n\n![](/ERC-website-2021/static/fusion_sensors_image3.png)\n\n## On the basis of Centralization Level (Where?)\n\n* **Centralized:** A single central unit deals with the fusion\n* **Decentralized:** Each sensor fuses the data and sends it onto the next one\n* **Distributed:** Each sensor fuses data locally and sends it to the next unit\n\n![](/ERC-website-2021/static/fusion_sensors_image2.png)\n\n## On the basis of Composition Level (What?)\n\n* **Competitive Fusion:** When different sensors are meant for the same purpose\n* **Complementary Fusion:** When different sensors are used to look at different scenes to obtain data that couldn‚Äôt have been obtained had the been used individually\n* **Coordinated Fusion:** Using multiple sensors to produce a new scene, but looking at the same object. E.g. 3D reconstruction\n\n![](/ERC-website-2021/static/fusion_sensors_image1.png)\n\nFor more details regarding the types of sensor fusion, check [here](https://www.thinkautonomous.ai/blog/?p=9-types-of-sensor-fusion-algorithms \"https://www.thinkautonomous.ai/blog/?p=9-types-of-sensor-fusion-algorithms\").\n\n**Example Calculation Regarding Sensor Fusion**\n\nFor a basic example showing how two measurements can be combined, check [this](https://en.wikipedia.org/wiki/Sensor_fusion#Example_calculations \"https://en.wikipedia.org/wiki/Sensor_fusion#Example_calculations\") section.\n\n# Algorithms on Sensor Fusion\n\n## Based on Sensor Fusion\n\n* The central limit theorem states that when we take a large number of measurements of a parameter, the distribution of their mean tends to a normal distribution, and the mean of the distribution gets closer to the true mean as number of measurements increase.\n* In order to see its relation to sensor fusion, assume we have two different sensors A and B. The more samples we take of their readings, the more closely the distribution of the sample averages will resemble a bell curve and thus approach the set‚Äôs true average value.  The closer we approach an accurate average value, the less noise will factor into sensor fusion algorithms.\n* For more information regarding the central limit theorem, check [here](https://en.wikipedia.org/wiki/Central_limit_theorem \"https://en.wikipedia.org/wiki/Central_limit_theorem\").\n\n## Based on Kalman Filter\n\n* A Kalman filter is an algorithm that estimates unknown values by taking data inputs from multiple sources, despite possibly having a high amount of signal noise.\n* It has the advantage of predicting unknown values more accurately by combining measurements than what is obtained on using the measurements individually.\n* The Kalman filter is a recursive algorithm that depends only on the previous state of the system and the current observed sensor data to estimate the current state of the system.\n* For more details regarding the Kalman filter, check [here](https://www.kalmanfilter.net/default.aspx \"https://www.kalmanfilter.net/default.aspx\") or [here](https://www.bzarg.com/p/how-a-kalman-filter-works-in-pictures/ \"https://www.bzarg.com/p/how-a-kalman-filter-works-in-pictures/\").\n\n## Based on Bayesian Networks\n\n* Bayes Rule in probability is the backbone of state update equations used for sensor fusion. Bayesian Networks based on Bayes rule predicts the likelihood that any given measurement is a contributing factor in determining a given parameter.\n* For a detailed study of Bayesian Networks, check [here](https://en.wikipedia.org/wiki/Bayesian_network \"https://en.wikipedia.org/wiki/Bayesian_network\").\n* Some of the algorithms used for Sensor Fusion based on Bayesian networks are [K2](http://web.cs.wpi.edu/\\~cs539/s05/Projects/k2_algorithm.pdf \"http://web.cs.wpi.edu/~cs539/s05/Projects/k2_algorithm.pdf\"), [hill climbing](https://www.geeksforgeeks.org/introduction-hill-climbing-artificial-intelligence/ \"https://www.geeksforgeeks.org/introduction-hill-climbing-artificial-intelligence/\"), [simulated annealing](https://en.wikipedia.org/wiki/Simulated_annealing \"https://en.wikipedia.org/wiki/Simulated_annealing\").\n\n## The Dempster-Shafer Theory\n\n* This theory, called the theory of belief functions or the evidence theory, is a general framework for working with uncertainties and measurements.\n* Dempster‚ÄìShafer theory is based on two ideas: obtaining degrees of belief for one question from subjective probabilities for a related question, and Dempster's rule for combining such degrees of belief when they are based on independent items of evidence.\n* For more details on this theory, check [here](https://en.wikipedia.org/wiki/Dempster%E2%80%93Shafer_theory \"https://en.wikipedia.org/wiki/Dempster%E2%80%93Shafer_theory\") or [here](https://www.geeksforgeeks.org/ml-dempster-shafer-theory/ \"https://www.geeksforgeeks.org/ml-dempster-shafer-theory/\").\n\n## Convolutional Neural Networks\n\n* Convolutional neural network based methods can simultaneously process many channels of sensor data. From this fusion of such data, they produce classification results based on image recognition.\n* For a detailed study of CNNs, check [here](https://towardsdatascience.com/a-comprehensive-guide-to-convolutional-neural-networks-the-eli5-way-3bd2b1164a53 \"https://towardsdatascience.com/a-comprehensive-guide-to-convolutional-neural-networks-the-eli5-way-3bd2b1164a53\").\n\n# Conclusion\n\nSensor Fusion is a vast field, with a huge number of algorithms to combine sensor data to obtain measurements. The mathematics behind sensor fusion is often complicated and requires a good understanding of concepts of probability. The goal of this article was to give a brief overview of different types of sensor fusion and to give a bird‚Äôs eye view of the various algorithms that can be used for sensor fusion.","slug":"sensor-fusion"},{"frontmatter":{"title":"SLAM","author":"Govind Saju","hero_image":"/ERC-website-2021/static/slam_cover.jpg","date":"2021-11-24T12:30:00.000Z"},"markdownBody":"The objective of SLAM is to estimate a robot‚Äôs state (position and orientation) and create a map of the robot‚Äôs surroundings simultaneously using the knowledge of its controls and the observations made by its sensors.\n\n# Introduction\n\nThe term SLAM is an acronym for ‚ÄúSimultaneous Localization and Mapping‚Äù.\n\n**Localization**: Localization refers to the robot's ability to estimate its own position and orientation with respect to its surroundings. This is done by combining the robot's controls along with the data obtained from its sensors.\n\n**Mapping**: Creating a map of the robot‚Äôs surroundings using its estimate on its position and the data obtained from various sensors.\n\nSLAM aims to do both of these tasks simultaneously, using one to help improve its estimate of the other. This may not sound possible, but there are various algorithms like [Kalman filter](https://en.wikipedia.org/wiki/Kalman_filter), [Particle filter](https://en.wikipedia.org/wiki/Particle_filter), and [GraphSLAM](https://people.eecs.berkeley.edu/\\~pabbeel/cs287-fa13/slides/GraphSLAM.pdf) that help provide an approximate solution in certain environments to both these problems.\n\nThe general idea of slam can be subdivided into different stages:\n\n* Landmark Extraction\n* Data Association\n* State Estimation\n* State Update\n* Landmark Update\n\n![](/ERC-website-2021/static/slam_image11.jpg)  \n\\*_In the image above, EKF stands for Extended Kalman Filter, an algorithm used for implementing SLAM._\n\nSLAM is an idea through which we estimate the robot‚Äôs state through its controls, and using the locations of the landmarks we witness, we improve the estimate of the robot's state. It is based on a probabilistic model, where each item has a probability of being in a particular position.\n\n# Applications of SLAM\n\n![](/ERC-website-2021/static/slam_image10.png)\n\nSLAM is used extensively in various indoor, outdoor, aerial, underwater and underground applications for both manned and unmanned vehicles.\n\nFor e.g. Reef monitoring, exploration of mines, surveillance drones, terrain mapping etc.\n\n# Probabilistic Interpretation of SLAM\n\nIn the probabilistic world, each measurement and estimate has some error associated with it, and we can only determine a probability distribution to estimate the map and localisation of a robot using SLAM. Mathematically, it can be represented as:\n\n![](/ERC-website-2021/static/slam_image14.png)\n\nThis means that the objective of SLAM is to obtain the probability distribution of the robot‚Äôs path and a map of its surroundings using the knowledge of the robot‚Äôs controls and the observations it makes using its sensors.\n\nBelow is a graphical representation of SLAM. **xt** is the location of the robot at time t, **m** represents the map, **ut** represents the controls of the robot at time t, and **zt** represents the values observed by the sensors on the robot.  \n![](/ERC-website-2021/static/slam_image6.png)\n\n# Homogeneous Coordinates\n\nIn SLAM, cameras are often used as sensors to obtain information about the robot's surroundings. Cameras don‚Äôt capture a 3D image, rather they capture a projection of the 3D world. The mathematical formulations can become simpler if we use projective geometry instead of euclidean geometry. The system of coordinates used in projective geometry is called homogeneous coordinates. The details regarding the mathematics of homogeneous coordinates can be found [here](https://en.wikipedia.org/wiki/Homogeneous_coordinates).\n\n# Bayes Filter\n\nA lot of the different models used for SLAM such as the Kalman Filter and the Particle Filter are based on the Recursive Bayes Filter. In the Bayes filter, the **belief** of **xt** is defined as\n\n![](/ERC-website-2021/static/slam_image8.png)\n\nThe recursive Bayes Filter can then be defined as a 2 step process:\n\n* Prediction Step\n\n  ![](/ERC-website-2021/static/slam_image12.png)\n* Correction Step  \n  ![](/ERC-website-2021/static/slam_image1.png)\n\n**_p_(_xt | ut_, _xt-1_)** represents the motion based model, which is the distribution of the current location based on the robot‚Äôs controls and its previous location. **_p_(_zt_ | _xt_)** represents the correction introduced based on the sensor readings **_zt_**. This Bayes filter acts as a framework for different realizations such as the Kalman Filter and the Particle Filter. For further details regarding the Bayes Filter, refer [here](https://en.wikipedia.org/wiki/Recursive_Bayesian_estimation).\n\n# Motion Models\n\nIn the section of Bayes Filter, we saw the term **_p_(_xt | ut_ , _xt-1_)** represents the motion based model. In general, there are 2 common types of motion based models:\n\n* Odometry based model\n* Velocity based model\n\nThe Odometry based model is mainly used for those robots that have wheel encoders, i.e. where it is feasible to count wheel motions and find the direction of motion. The Velocity based model is normally used where the odometry based model cannot be implemented, e.g. a drone does not have wheels and wheel encoders cannot be used. For a detailed description of the 2 models here including their mathematical formulations, check [this](https://ccc.inaoep.mx/\\~mdprl/documentos/CH5.pdf) document.\n\n# Sensor Models\n\nThe term **_p_(_zt_ | _xt_** **)** represents the sensor based model. It represents the probability distribution of getting a measurement **_zt_** at a position **_xt ._** There can be different kinds of sensors used.\n\n* Internal sensors such as gyroscopes, accelerometers etc\n* Proximity sensors such as Sonar, Radar etc.\n* Visual Sensors like cameras\n* Satellite based sensors like GPS\n\nFor more details regarding the Sensor Models, refer to [this](http://ais.informatik.uni-freiburg.de/teaching/ss09/robotics/slides/e_sensor-models.pdf) document.\n\n![](/ERC-website-2021/static/slam_image2.jpg)\n\n# Filters\n\nThere are 2 main methods used for implementing SLAM, that is the Kalman Filter and the Particle Filter. They are based on the Bayes Filter and use the motion and sensor models to get a good estimate for SLAM.\n\n# The Kalman Filter\n\nThe Kalman filter is a filter based on the Bayes filter, and is the optimal solution for the linear Gaussian case. It assumes all probability distributions are gaussian. For a complete tutorial on Kalman filter, check [here](https://www.kalmanfilter.net/default.aspx). In short, the Kalman filter can be depicted as follows:\n\n![](/ERC-website-2021/static/slam_image3.png)![](/ERC-website-2021/static/slam_image5.png)\n\n# Particle Filter\n\nThe particle filter is also based on the Bayes filter, but it is superior to the Kalman filter in non-linear and non-Gaussian systems. The particle filter models by samples, and the more samples, the better the distribution.\n\n![](/ERC-website-2021/static/slam_image4.png)![](/ERC-website-2021/static/slam_image7.png)  \nFor more details regarding the particle filter, check [here](https://en.wikipedia.org/wiki/Particle_filter) or [here](http://ais.informatik.uni-freiburg.de/teaching/ws13/mapping/pdf/slam11-particle-filter.pdf).\n\n# Further Reading\n\nFor tutorials on the Kalman Filter: check [here](http://www.kalmanfilter.net) or [here](https://www.bzarg.com/p/how-a-kalman-filter-works-in-pictures/).\n\nFor a reading on the Particle Filter: check [here](https://towardsdatascience.com/particle-filter-a-hero-in-the-world-of-non-linearity-and-non-gaussian-6d8947f4a3dc) or the resources mentioned in the particle filter section.\n\nFor a reading on the Extended Kalman Filter, check [here](https://en.wikipedia.org/wiki/Extended_Kalman_filter).\n\nFor a complete course on SLAM including slides and recordings from the University of Freiburg, check [here](http://ais.informatik.uni-freiburg.de/teaching/ws13/mapping/).","slug":"slam"}],"title":"ERC: Blog","description":"Electronics and Robotics Club, IIT Bombay's Blog"},"__N_SSG":true}