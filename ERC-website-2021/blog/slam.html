<!DOCTYPE html><html><head><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.14.0/css/all.css" integrity="sha384-HzLeBuhoNPvSl5KYnjx0BT+WB0QEEqLprO+NBkkk5gbc67FTaL7XIGa2w1L0Xbgc" crossorigin="anonymous"/><meta name="viewport" content="width=device-width, initial-scale=1" class="jsx-5c406e1c43a4c1e0"/><meta charSet="utf-8" class="jsx-5c406e1c43a4c1e0"/><title class="jsx-5c406e1c43a4c1e0">ERC: SLAM</title><meta name="Description" class="jsx-5c406e1c43a4c1e0"/><meta name="next-head-count" content="4"/><link rel="preload" href="/ERC-website-2021/_next/static/css/1e14cc6db1e7a797.css" as="style"/><link rel="stylesheet" href="/ERC-website-2021/_next/static/css/1e14cc6db1e7a797.css" data-n-g=""/><link rel="preload" href="/ERC-website-2021/_next/static/css/b4c3d7a1b2745c28.css" as="style"/><link rel="stylesheet" href="/ERC-website-2021/_next/static/css/b4c3d7a1b2745c28.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/ERC-website-2021/_next/static/chunks/polyfills-5cd94c89d3acac5f.js"></script><script src="/ERC-website-2021/_next/static/chunks/webpack-fa43d853eceb8330.js" defer=""></script><script src="/ERC-website-2021/_next/static/chunks/framework-91d7f78b5b4003c8.js" defer=""></script><script src="/ERC-website-2021/_next/static/chunks/main-7f98c67519643b43.js" defer=""></script><script src="/ERC-website-2021/_next/static/chunks/pages/_app-8cb99849f9af73f7.js" defer=""></script><script src="/ERC-website-2021/_next/static/chunks/147-3e7b67f404388648.js" defer=""></script><script src="/ERC-website-2021/_next/static/chunks/157-8d95c7b28c8fe8df.js" defer=""></script><script src="/ERC-website-2021/_next/static/chunks/pages/blog/%5Bslug%5D-771aa725b6e9cc01.js" defer=""></script><script src="/ERC-website-2021/_next/static/5QJC4znxUt28OyN5o0qMk/_buildManifest.js" defer=""></script><script src="/ERC-website-2021/_next/static/5QJC4znxUt28OyN5o0qMk/_ssgManifest.js" defer=""></script><script src="/ERC-website-2021/_next/static/5QJC4znxUt28OyN5o0qMk/_middlewareManifest.js" defer=""></script><style id="__jsx-5c406e1c43a4c1e0">@import url("https://fonts.googleapis.com/css?family=Work+Sans&display=swap");
* {box-sizing:inherit}
html {box-sizing:border-box;
overflow-y:scroll}
body {margin:0;
font-family:"Work Sans", "Helvetica Neue", Helvetica, sans-serif;
overflow-x:hidden;
color:#000;
font-size:16px;
-webkit-font-smoothing:antialiased;
-moz-osx-font-smoothing:grayscale}
a {-webkit-text-decoration:none;
text-decoration:none;
color:inherit;
-webkit-transition:opacity 0.2s ease;
transition:opacity 0.2s ease}
a:hover {-webkit-transition:opacity 0.2s ease;
transition:opacity 0.2s ease;
opacity:0.5;
text-decoration-color:inherit}
ul {list-style:none;
margin:0;
padding-bottom:0;
padding-left:0;
padding-right:0;
padding-top:0;
list-style-position:outside;
list-style-image:none}
ol {margin:0;
padding-bottom:0;
padding-left:0;
padding-right:0;
padding-top:0;
list-style-position:outside;
list-style-image:none}
ul, ol, p {margin-bottom:1.45rem}
img {max-width:100%}
img, figure, table, fieldset {margin-left:0;
margin-right:0;
margin-top:0;
padding-bottom:0;
padding-left:0;
padding-right:0;
padding-top:0;
margin-bottom:1.45rem}
pre {margin-left:0;
margin-right:0;
margin-top:0;
margin-bottom:1.45rem;
font-size:0.85rem;
line-height:1.42;
background:hsla(0, 0%, 0%, 0.04);
border-radius:3px;
overflow:auto;
word-wrap:normal;
padding:1.45rem}
table {font-size:1rem;
line-height:1.45rem;
border-collapse:collapse;
width:100%}
blockquote {margin-left:1.45rem;
margin-right:1.45rem;
margin-top:0;
padding-bottom:0;
padding-left:0;
padding-right:0;
padding-top:0;
margin-bottom:1.45rem}
strong {font-weight:bold}
li {margin-bottom:calc(1.45rem / 2)}
ol li {padding-left:0}
ul li {padding-left:0}
li >ol {margin-left:1.45rem;
margin-bottom:calc(1.45rem / 2);
margin-top:calc(1.45rem / 2)}
li >ul {margin-left:1.45rem;
margin-bottom:calc(1.45rem / 2);
margin-top:calc(1.45rem / 2)}
blockquote *:last-child {margin-bottom:0}
li *:last-child {margin-bottom:0}
p *:last-child {margin-bottom:0}
li >p {margin-bottom:calc(1.45rem / 2)}
code {font-size:0.85rem;
line-height:1.45rem}
h1, h2, h3, h4, h5, h6, p {font-family:"Work Sans", "Helvetica Neue", Helvetica, sans-serif;
margin-left:0;
margin-right:0;
margin-top:0;
padding-bottom:0;
padding-left:0;
padding-right:0;
padding-top:0;
margin-bottom:1.45rem;
color:inherit;
text-rendering:optimizeLegibility}
h1, h2 {font-weight:500}
h1 {font-size:2rem;
letter-spacing:-1px;
line-height:1.1875}
h2 {font-size:1.7rem;
letter-spacing:-0.75px;
line-height:1.2}
h3 {font-size:1.2rem;
letter-spacing:-0.5px;
line-height:1.1875;
color:#ffffff;
font-weight:normal}
p {font-size:1.2rem;
letter-spacing:-0.5px;
line-height:1.5;
color:#ffffff}
@media (min-width:1280px) {h1 {font-size:2rem;
letter-spacing:-1px;
line-height:1.1875}
h2 {font-size:1.5rem;
letter-spacing:-0.75px;
line-height:1.1667}
h3 {font-size:1rem;
letter-spacing:-0.5px;
line-height:1.1875;
color:#ffffff;
font-weight:normal}
p {line-height:1.4375}}</style><style id="__jsx-fad75cd775d05681">.blog.jsx-fad75cd775d05681 {background-color:#1D252E;
color:#ffffff;
margin-bottom:0}
.blog.jsx-fad75cd775d05681 h1.jsx-fad75cd775d05681 {margin-bottom:0.7rem}
.blog__hero.jsx-fad75cd775d05681 {min-height:300px;
height:60vh;
width:100%;
margin:0;
overflow:hidden}
.blog__hero.jsx-fad75cd775d05681 img.jsx-fad75cd775d05681 {margin-bottom:0;
object-fit:cover;
min-height:100%;
min-width:100%;
object-position:center}
.blog__info.jsx-fad75cd775d05681 {padding:1.5rem 1.25rem;
width:100%;
max-width:768px;
margin:0 auto}
.blog__info.jsx-fad75cd775d05681 h1.jsx-fad75cd775d05681 {margin-bottom:0.66rem}
.blog__info.jsx-fad75cd775d05681 h3.jsx-fad75cd775d05681 {margin-bottom:0}
.blog__body.jsx-fad75cd775d05681 {width:100%;
padding:0 1.25rem;
margin:0 auto;
display:-webkit-box;
display:-webkit-flex;
display:-ms-flexbox;
display:flex;
-webkit-flex-direction:column;
-ms-flex-direction:column;
flex-direction:column;
-webkit-justify-content:center;
justify-content:center}
.blog__body.jsx-fad75cd775d05681 a.jsx-fad75cd775d05681 {padding-bottom:1.5rem}
.blog__body.jsx-fad75cd775d05681:last-child {margin-bottom:0}
.blog__body.jsx-fad75cd775d05681 h1.jsx-fad75cd775d05681 h2.jsx-fad75cd775d05681 h3.jsx-fad75cd775d05681 h4.jsx-fad75cd775d05681 h5.jsx-fad75cd775d05681 h6.jsx-fad75cd775d05681 p.jsx-fad75cd775d05681 {font-weight:normal}
.blog__body.jsx-fad75cd775d05681 p.jsx-fad75cd775d05681 {color:#ffffff}
.blog__body.jsx-fad75cd775d05681 ul.jsx-fad75cd775d05681 {list-style:initial}
.blog__body.jsx-fad75cd775d05681 ul.jsx-fad75cd775d05681 ol.jsx-fad75cd775d05681 {margin-left:1.25rem;
margin-bottom:1.25rem;
padding-left:1.45rem}
.blog__footer.jsx-fad75cd775d05681 {display:-webkit-box;
display:-webkit-flex;
display:-ms-flexbox;
display:flex;
-webkit-box-pack:justify;
-webkit-justify-content:space-between;
justify-content:space-between;
-webkit-align-items:center;
-webkit-box-align:center;
-ms-flex-align:center;
align-items:center;
padding:1.5rem 1.25rem;
width:100%;
max-width:800px;
margin:0 auto}
.blog__footer.jsx-fad75cd775d05681 h2.jsx-fad75cd775d05681 {margin-bottom:0}
.blog__footer.jsx-fad75cd775d05681 a.jsx-fad75cd775d05681 {display:-webkit-box;
display:-webkit-flex;
display:-ms-flexbox;
display:flex;
-webkit-box-pack:justify;
-webkit-justify-content:space-between;
justify-content:space-between;
-webkit-align-items:center;
-webkit-box-align:center;
-ms-flex-align:center;
align-items:center}
.blog__footer.jsx-fad75cd775d05681 a.jsx-fad75cd775d05681 svg.jsx-fad75cd775d05681 {width:20px}
@media (min-width:768px) {.blog.jsx-fad75cd775d05681 {display:-webkit-box;
display:-webkit-flex;
display:-ms-flexbox;
display:flex;
-webkit-flex-direction:column;
-ms-flex-direction:column;
flex-direction:column}
.blog__body.jsx-fad75cd775d05681 {max-width:800px;
padding:0 2rem}
.blog__body.jsx-fad75cd775d05681 span.jsx-fad75cd775d05681 {width:100%;
margin:1.5rem auto}
.blog__body.jsx-fad75cd775d05681 ul.jsx-fad75cd775d05681 ol.jsx-fad75cd775d05681 {margin-left:1.5rem;
margin-bottom:1.5rem}
.blog__hero.jsx-fad75cd775d05681 {min-height:600px;
height:75vh}
.blog__info.jsx-fad75cd775d05681 {text-align:center;
padding:2rem 0}
.blog__info.jsx-fad75cd775d05681 h1.jsx-fad75cd775d05681 {max-width:500px;
margin:0 auto 0.66rem auto}
.blog__footer.jsx-fad75cd775d05681 {padding:2.25rem}}
@media (min-width:1440px) {.blog__hero.jsx-fad75cd775d05681 {height:70vh}
.blog__info.jsx-fad75cd775d05681 {padding:3rem 0}
.blog__footer.jsx-fad75cd775d05681 {padding:2rem 2rem 3rem 2rem}}</style><style id="__jsx-906dc5424778ca56">.layout.jsx-906dc5424778ca56 {overflow-x:hidden;
display:-webkit-box;
display:-webkit-flex;
display:-ms-flexbox;
display:flex;
-webkit-flex-direction:column;
-ms-flex-direction:column;
flex-direction:column;
min-height:100vh}
.layout.jsx-906dc5424778ca56 .info_page.jsx-906dc5424778ca56 {color:#ebebeb}
.content.jsx-906dc5424778ca56 {-webkit-box-flex:1;
-webkit-flex-grow:1;
-ms-flex-positive:1;
flex-grow:1}
@media (min-width:768px) {.layout.jsx-906dc5424778ca56 {display:block}
.content.jsx-906dc5424778ca56 {-webkit-box-flex:none;
-webkit-flex-grow:none;
-ms-flex-positive:none;
flex-grow:none;
width:100vw;
margin-left:0vw}}</style></head><body><div id="__next"><section style="background-color:undefined;color:false" class="jsx-906dc5424778ca56 layout false"><nav class="NavBar_navbar__D1PWG"><ul class="NavBar_list__ZV9KR"><li class="NavBar_buttons_view__Rf_gB"><a href="https://erciitb.github.io/website-2020/#home">Home</a></li><li class="NavBar_buttons_view__Rf_gB"><a href="/ERC-website-2021/blog">Blog</a></li><li class="NavBar_buttons_view__Rf_gB"><a href="https://erciitb.github.io/website-2020/#events">Events</a></li><li class="NavBar_buttons_view__Rf_gB"><a href="https://erciitb.github.io/website-2020/#ercteamdet">Team Details</a></li><li class="NavBar_buttons_view__Rf_gB"><a href="https://erciitb.github.io/website-2020/#contact">Contact Us</a></li></ul></nav><div class="NavBar_navbar_mobile__9duUE"><div class="NavBar_hamburger_icon_block__a5VwY"><button href="/" class="NavBar_hamburger_icon_button__3TwpQ">☰</button></div><nav class="NavBar_nav_menu___omdq"><ul class="NavBar_nav_menu_items__gPV7x"><li class="NavBar_buttons_view__Rf_gB"><a href="/ERC-website-2021/blog/slam#">Close ×</a></li><li class="NavBar_buttons_view__Rf_gB"><a href="https://erciitb.github.io/website-2020/#home">Home</a></li><li class="NavBar_buttons_view__Rf_gB"><a href="/ERC-website-2021/blog">Blog</a></li><li class="NavBar_buttons_view__Rf_gB"><a href="https://erciitb.github.io/website-2020/#events">Events</a></li><li class="NavBar_buttons_view__Rf_gB"><a href="https://erciitb.github.io/website-2020/#ercteamdet">Team Details</a></li><li class="NavBar_buttons_view__Rf_gB"><a href="https://erciitb.github.io/website-2020/#contact">Contact Us</a></li></ul></nav></div><div class="jsx-906dc5424778ca56 content"><article class="jsx-fad75cd775d05681 blog"><figure class="jsx-fad75cd775d05681 blog__hero"><img src="/ERC-website-2021/static/slam_cover.jpg" alt="blog_hero_SLAM" class="jsx-fad75cd775d05681"/></figure><div class="jsx-fad75cd775d05681 blog__info"><h1 class="jsx-fad75cd775d05681">SLAM</h1><h3 class="jsx-fad75cd775d05681">Nov 24 2021</h3></div><div class="jsx-fad75cd775d05681 blog__body"><p>The objective of SLAM is to estimate a robot’s state (position and orientation) and create a map of the robot’s surroundings simultaneously using the knowledge of its controls and the observations made by its sensors.</p><h1>Introduction</h1><p>The term SLAM is an acronym for “Simultaneous Localization and Mapping”.</p><p><strong>Localization</strong>: Localization refers to the robot&#x27;s ability to estimate its own position and orientation with respect to its surroundings. This is done by combining the robot&#x27;s controls along with the data obtained from its sensors.</p><p><strong>Mapping</strong>: Creating a map of the robot’s surroundings using its estimate on its position and the data obtained from various sensors.</p><p>SLAM aims to do both of these tasks simultaneously, using one to help improve its estimate of the other. This may not sound possible, but there are various algorithms like <a href="https://en.wikipedia.org/wiki/Kalman_filter">Kalman filter</a>, <a href="https://en.wikipedia.org/wiki/Particle_filter">Particle filter</a>, and <a href="https://people.eecs.berkeley.edu/~pabbeel/cs287-fa13/slides/GraphSLAM.pdf">GraphSLAM</a> that help provide an approximate solution in certain environments to both these problems.</p><p>The general idea of slam can be subdivided into different stages:</p><ul><li>Landmark Extraction</li><li>Data Association</li><li>State Estimation</li><li>State Update</li><li>Landmark Update</li></ul><p><img src="/ERC-website-2021/static/slam_image11.jpg"/><br/>*<em>In the image above, EKF stands for Extended Kalman Filter, an algorithm used for implementing SLAM.</em></p><p>SLAM is an idea through which we estimate the robot’s state through its controls, and using the locations of the landmarks we witness, we improve the estimate of the robot&#x27;s state. It is based on a probabilistic model, where each item has a probability of being in a particular position.</p><h1>Applications of SLAM</h1><p><img src="/ERC-website-2021/static/slam_image10.png"/></p><p>SLAM is used extensively in various indoor, outdoor, aerial, underwater and underground applications for both manned and unmanned vehicles.</p><p>For e.g. Reef monitoring, exploration of mines, surveillance drones, terrain mapping etc.</p><h1>Probabilistic Interpretation of SLAM</h1><p>In the probabilistic world, each measurement and estimate has some error associated with it, and we can only determine a probability distribution to estimate the map and localisation of a robot using SLAM. Mathematically, it can be represented as:</p><p><img src="/ERC-website-2021/static/slam_image14.png"/></p><p>This means that the objective of SLAM is to obtain the probability distribution of the robot’s path and a map of its surroundings using the knowledge of the robot’s controls and the observations it makes using its sensors.</p><p>Below is a graphical representation of SLAM. <strong>xt</strong> is the location of the robot at time t, <strong>m</strong> represents the map, <strong>ut</strong> represents the controls of the robot at time t, and <strong>zt</strong> represents the values observed by the sensors on the robot.<br/><img src="/ERC-website-2021/static/slam_image6.png"/></p><h1>Homogeneous Coordinates</h1><p>In SLAM, cameras are often used as sensors to obtain information about the robot&#x27;s surroundings. Cameras don’t capture a 3D image, rather they capture a projection of the 3D world. The mathematical formulations can become simpler if we use projective geometry instead of euclidean geometry. The system of coordinates used in projective geometry is called homogeneous coordinates. The details regarding the mathematics of homogeneous coordinates can be found <a href="https://en.wikipedia.org/wiki/Homogeneous_coordinates">here</a>.</p><h1>Bayes Filter</h1><p>A lot of the different models used for SLAM such as the Kalman Filter and the Particle Filter are based on the Recursive Bayes Filter. In the Bayes filter, the <strong>belief</strong> of <strong>xt</strong> is defined as</p><p><img src="/ERC-website-2021/static/slam_image8.png"/></p><p>The recursive Bayes Filter can then be defined as a 2 step process:</p><ul><li><p>Prediction Step</p><p><img src="/ERC-website-2021/static/slam_image12.png"/></p></li><li><p>Correction Step<br/><img src="/ERC-website-2021/static/slam_image1.png"/></p></li></ul><p><strong><em>p</em>(<em>xt | ut</em>, <em>xt-1</em>)</strong> represents the motion based model, which is the distribution of the current location based on the robot’s controls and its previous location. <strong><em>p</em>(<em>zt</em> | <em>xt</em>)</strong> represents the correction introduced based on the sensor readings <strong><em>zt</em></strong>. This Bayes filter acts as a framework for different realizations such as the Kalman Filter and the Particle Filter. For further details regarding the Bayes Filter, refer <a href="https://en.wikipedia.org/wiki/Recursive_Bayesian_estimation">here</a>.</p><h1>Motion Models</h1><p>In the section of Bayes Filter, we saw the term <strong><em>p</em>(<em>xt | ut</em> , <em>xt-1</em>)</strong> represents the motion based model. In general, there are 2 common types of motion based models:</p><ul><li>Odometry based model</li><li>Velocity based model</li></ul><p>The Odometry based model is mainly used for those robots that have wheel encoders, i.e. where it is feasible to count wheel motions and find the direction of motion. The Velocity based model is normally used where the odometry based model cannot be implemented, e.g. a drone does not have wheels and wheel encoders cannot be used. For a detailed description of the 2 models here including their mathematical formulations, check <a href="https://ccc.inaoep.mx/~mdprl/documentos/CH5.pdf">this</a> document.</p><h1>Sensor Models</h1><p>The term <strong><em>p</em>(<em>zt</em> | <em>xt</em></strong> <strong>)</strong> represents the sensor based model. It represents the probability distribution of getting a measurement <strong><em>zt</em></strong> at a position <strong><em>xt .</em></strong> There can be different kinds of sensors used.</p><ul><li>Internal sensors such as gyroscopes, accelerometers etc</li><li>Proximity sensors such as Sonar, Radar etc.</li><li>Visual Sensors like cameras</li><li>Satellite based sensors like GPS</li></ul><p>For more details regarding the Sensor Models, refer to <a href="http://ais.informatik.uni-freiburg.de/teaching/ss09/robotics/slides/e_sensor-models.pdf">this</a> document.</p><p><img src="/ERC-website-2021/static/slam_image2.jpg"/></p><h1>Filters</h1><p>There are 2 main methods used for implementing SLAM, that is the Kalman Filter and the Particle Filter. They are based on the Bayes Filter and use the motion and sensor models to get a good estimate for SLAM.</p><h1>The Kalman Filter</h1><p>The Kalman filter is a filter based on the Bayes filter, and is the optimal solution for the linear Gaussian case. It assumes all probability distributions are gaussian. For a complete tutorial on Kalman filter, check <a href="https://www.kalmanfilter.net/default.aspx">here</a>. In short, the Kalman filter can be depicted as follows:</p><p><img src="/ERC-website-2021/static/slam_image3.png"/><img src="/ERC-website-2021/static/slam_image5.png"/></p><h1>Particle Filter</h1><p>The particle filter is also based on the Bayes filter, but it is superior to the Kalman filter in non-linear and non-Gaussian systems. The particle filter models by samples, and the more samples, the better the distribution.</p><p><img src="/ERC-website-2021/static/slam_image4.png"/><img src="/ERC-website-2021/static/slam_image7.png"/><br/>For more details regarding the particle filter, check <a href="https://en.wikipedia.org/wiki/Particle_filter">here</a> or <a href="http://ais.informatik.uni-freiburg.de/teaching/ws13/mapping/pdf/slam11-particle-filter.pdf">here</a>.</p><h1>Further Reading</h1><p>For tutorials on the Kalman Filter: check <a href="http://www.kalmanfilter.net">here</a> or <a href="https://www.bzarg.com/p/how-a-kalman-filter-works-in-pictures/">here</a>.</p><p>For a reading on the Particle Filter: check <a href="https://towardsdatascience.com/particle-filter-a-hero-in-the-world-of-non-linearity-and-non-gaussian-6d8947f4a3dc">here</a> or the resources mentioned in the particle filter section.</p><p>For a reading on the Extended Kalman Filter, check <a href="https://en.wikipedia.org/wiki/Extended_Kalman_filter">here</a>.</p><p>For a complete course on SLAM including slides and recordings from the University of Freiburg, check <a href="http://ais.informatik.uni-freiburg.de/teaching/ws13/mapping/">here</a>.</p></div><h2 class="jsx-fad75cd775d05681 blog__footer">Written By: <!-- -->Govind Saju</h2></article></div><div class="contact-section" id="contact"><div class="contact-details"><p id="contact-text" class="hover-difference">Get directly in touch with us:</p><div class="contact-icons hover-difference"><a href="https://www.facebook.com/erciitb"><i class="fab fa-facebook-square"></i></a><a href="https://www.instagram.com/erc.iitb/"><i class="fab fa-instagram"></i></a><a href="mailto:erciitbombay@gmail.com"><i class="far fa-envelope"></i></a></div><a href="mailto:elecrobo.club@iitb.ac.in" id="contact-mail" class="hover-difference">elecrobo.club@iitb.ac.in</a><button class="contact-form-button">Message us</button></div><div class="contact-form-map-mix-outer"><div class="contact-form-map-mix-inner"><div class="contact-map"><iframe src="https://www.google.com/maps/embed?pb=!1m18!1m12!1m3!1d3169.6786880670256!2d72.9138437580561!3d19.13376545835707!2m3!1f0!2f0!3f0!3m2!1i1024!2i768!4f13.1!3m3!1m2!1s0x3be7c7f5e4ac7efd%3A0xd9d02f29b4617fb4!2sTinkerers&#x27;%20Laboratory!5e0!3m2!1sen!2sin!4v1597995010048!5m2!1sen!2sin" frameBorder="0" style="border:0" aria-hidden="false" tabindex="0"></iframe></div><div class="contact-form"><form action="./form-submit.php" method="POST" id="validated-form"><div class="contact-form-element"><label for="name">Name</label><input type="text" name="name" id="contact-user-name" required=""/></div><div class="contact-form-element"><label for="email">Email</label><input type="text" name="email" id="contact-user-email" required=""/></div><div class="contact-form-element"><label for="message">Message</label><textarea name="message" maxlength="10000" cols="30" rows="4" id="contact-user-message"></textarea></div></form></div></div></div></div></section></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"siteTitle":"ERC: SLAM","frontmatter":{"title":"SLAM","author":"Govind Saju","hero_image":"/ERC-website-2021/static/slam_cover.jpg","date":"2021-11-24T12:30:00.000Z"},"markdownBody":"The objective of SLAM is to estimate a robot’s state (position and orientation) and create a map of the robot’s surroundings simultaneously using the knowledge of its controls and the observations made by its sensors.\n\n# Introduction\n\nThe term SLAM is an acronym for “Simultaneous Localization and Mapping”.\n\n**Localization**: Localization refers to the robot's ability to estimate its own position and orientation with respect to its surroundings. This is done by combining the robot's controls along with the data obtained from its sensors.\n\n**Mapping**: Creating a map of the robot’s surroundings using its estimate on its position and the data obtained from various sensors.\n\nSLAM aims to do both of these tasks simultaneously, using one to help improve its estimate of the other. This may not sound possible, but there are various algorithms like [Kalman filter](https://en.wikipedia.org/wiki/Kalman_filter), [Particle filter](https://en.wikipedia.org/wiki/Particle_filter), and [GraphSLAM](https://people.eecs.berkeley.edu/\\~pabbeel/cs287-fa13/slides/GraphSLAM.pdf) that help provide an approximate solution in certain environments to both these problems.\n\nThe general idea of slam can be subdivided into different stages:\n\n* Landmark Extraction\n* Data Association\n* State Estimation\n* State Update\n* Landmark Update\n\n![](/ERC-website-2021/static/slam_image11.jpg)  \n\\*_In the image above, EKF stands for Extended Kalman Filter, an algorithm used for implementing SLAM._\n\nSLAM is an idea through which we estimate the robot’s state through its controls, and using the locations of the landmarks we witness, we improve the estimate of the robot's state. It is based on a probabilistic model, where each item has a probability of being in a particular position.\n\n# Applications of SLAM\n\n![](/ERC-website-2021/static/slam_image10.png)\n\nSLAM is used extensively in various indoor, outdoor, aerial, underwater and underground applications for both manned and unmanned vehicles.\n\nFor e.g. Reef monitoring, exploration of mines, surveillance drones, terrain mapping etc.\n\n# Probabilistic Interpretation of SLAM\n\nIn the probabilistic world, each measurement and estimate has some error associated with it, and we can only determine a probability distribution to estimate the map and localisation of a robot using SLAM. Mathematically, it can be represented as:\n\n![](/ERC-website-2021/static/slam_image14.png)\n\nThis means that the objective of SLAM is to obtain the probability distribution of the robot’s path and a map of its surroundings using the knowledge of the robot’s controls and the observations it makes using its sensors.\n\nBelow is a graphical representation of SLAM. **xt** is the location of the robot at time t, **m** represents the map, **ut** represents the controls of the robot at time t, and **zt** represents the values observed by the sensors on the robot.  \n![](/ERC-website-2021/static/slam_image6.png)\n\n# Homogeneous Coordinates\n\nIn SLAM, cameras are often used as sensors to obtain information about the robot's surroundings. Cameras don’t capture a 3D image, rather they capture a projection of the 3D world. The mathematical formulations can become simpler if we use projective geometry instead of euclidean geometry. The system of coordinates used in projective geometry is called homogeneous coordinates. The details regarding the mathematics of homogeneous coordinates can be found [here](https://en.wikipedia.org/wiki/Homogeneous_coordinates).\n\n# Bayes Filter\n\nA lot of the different models used for SLAM such as the Kalman Filter and the Particle Filter are based on the Recursive Bayes Filter. In the Bayes filter, the **belief** of **xt** is defined as\n\n![](/ERC-website-2021/static/slam_image8.png)\n\nThe recursive Bayes Filter can then be defined as a 2 step process:\n\n* Prediction Step\n\n  ![](/ERC-website-2021/static/slam_image12.png)\n* Correction Step  \n  ![](/ERC-website-2021/static/slam_image1.png)\n\n**_p_(_xt | ut_, _xt-1_)** represents the motion based model, which is the distribution of the current location based on the robot’s controls and its previous location. **_p_(_zt_ | _xt_)** represents the correction introduced based on the sensor readings **_zt_**. This Bayes filter acts as a framework for different realizations such as the Kalman Filter and the Particle Filter. For further details regarding the Bayes Filter, refer [here](https://en.wikipedia.org/wiki/Recursive_Bayesian_estimation).\n\n# Motion Models\n\nIn the section of Bayes Filter, we saw the term **_p_(_xt | ut_ , _xt-1_)** represents the motion based model. In general, there are 2 common types of motion based models:\n\n* Odometry based model\n* Velocity based model\n\nThe Odometry based model is mainly used for those robots that have wheel encoders, i.e. where it is feasible to count wheel motions and find the direction of motion. The Velocity based model is normally used where the odometry based model cannot be implemented, e.g. a drone does not have wheels and wheel encoders cannot be used. For a detailed description of the 2 models here including their mathematical formulations, check [this](https://ccc.inaoep.mx/\\~mdprl/documentos/CH5.pdf) document.\n\n# Sensor Models\n\nThe term **_p_(_zt_ | _xt_** **)** represents the sensor based model. It represents the probability distribution of getting a measurement **_zt_** at a position **_xt ._** There can be different kinds of sensors used.\n\n* Internal sensors such as gyroscopes, accelerometers etc\n* Proximity sensors such as Sonar, Radar etc.\n* Visual Sensors like cameras\n* Satellite based sensors like GPS\n\nFor more details regarding the Sensor Models, refer to [this](http://ais.informatik.uni-freiburg.de/teaching/ss09/robotics/slides/e_sensor-models.pdf) document.\n\n![](/ERC-website-2021/static/slam_image2.jpg)\n\n# Filters\n\nThere are 2 main methods used for implementing SLAM, that is the Kalman Filter and the Particle Filter. They are based on the Bayes Filter and use the motion and sensor models to get a good estimate for SLAM.\n\n# The Kalman Filter\n\nThe Kalman filter is a filter based on the Bayes filter, and is the optimal solution for the linear Gaussian case. It assumes all probability distributions are gaussian. For a complete tutorial on Kalman filter, check [here](https://www.kalmanfilter.net/default.aspx). In short, the Kalman filter can be depicted as follows:\n\n![](/ERC-website-2021/static/slam_image3.png)![](/ERC-website-2021/static/slam_image5.png)\n\n# Particle Filter\n\nThe particle filter is also based on the Bayes filter, but it is superior to the Kalman filter in non-linear and non-Gaussian systems. The particle filter models by samples, and the more samples, the better the distribution.\n\n![](/ERC-website-2021/static/slam_image4.png)![](/ERC-website-2021/static/slam_image7.png)  \nFor more details regarding the particle filter, check [here](https://en.wikipedia.org/wiki/Particle_filter) or [here](http://ais.informatik.uni-freiburg.de/teaching/ws13/mapping/pdf/slam11-particle-filter.pdf).\n\n# Further Reading\n\nFor tutorials on the Kalman Filter: check [here](http://www.kalmanfilter.net) or [here](https://www.bzarg.com/p/how-a-kalman-filter-works-in-pictures/).\n\nFor a reading on the Particle Filter: check [here](https://towardsdatascience.com/particle-filter-a-hero-in-the-world-of-non-linearity-and-non-gaussian-6d8947f4a3dc) or the resources mentioned in the particle filter section.\n\nFor a reading on the Extended Kalman Filter, check [here](https://en.wikipedia.org/wiki/Extended_Kalman_filter).\n\nFor a complete course on SLAM including slides and recordings from the University of Freiburg, check [here](http://ais.informatik.uni-freiburg.de/teaching/ws13/mapping/)."},"__N_SSG":true},"page":"/blog/[slug]","query":{"slug":"slam"},"buildId":"5QJC4znxUt28OyN5o0qMk","assetPrefix":"/ERC-website-2021","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>